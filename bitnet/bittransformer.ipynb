{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BitNetTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from bitnet import BitNetTransformer\n",
    "\n",
    "from app.utils import clear_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bertimbau Tokenizer & Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "huggingface_model = \"neuralmind/bert-base-portuguese-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(huggingface_model)\n",
    "model = AutoModel.from_pretrained(huggingface_model)\n",
    "feature_extractor = pipeline('feature-extraction', model=model, tokenizer=tokenizer)\n",
    "embeddings = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29794\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)\n",
    "print(embeddings.embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando diferentes maneiras de transformar texto para embbedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'O advogado apresentou recurso para o juíz'\n",
    "\n",
    "# a. contextualized embeddings c/ feature_extractor: texto tokenizado automaticamente, passa para embedding, encoder e attention layers antes\n",
    "sentence_embeddings1 = feature_extractor(sentence)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    sentence_tokenized = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    sentence_input_ids = sentence_tokenized[\"input_ids\"]\n",
    "    sentence_attention_mask = sentence_tokenized[\"attention_mask\"]\n",
    "\n",
    "    # b. non-contextualized embeddings com embedding layer do bertimbau: usa embbeding layer \n",
    "    # antes de passar na rede transformer, ou seja, sem passar pelo encoder e attention layers\n",
    "    sentence_embeddings2 = embeddings(sentence_input_ids)\n",
    "\n",
    "    # c. a mesma coisa da primeira abordagem só que mais explicita, sem as facilidades do pipeline\n",
    "    sentence_embeddings3 = model(input_ids=sentence_input_ids, \n",
    "                                attention_mask=sentence_attention_mask\n",
    "                                ).last_hidden_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch sizes:\n",
      "1\n",
      "1\n",
      "1\n",
      "Sequence Lengths:\n",
      "10\n",
      "10\n",
      "10\n",
      "BERT Hidden Size:\n",
      "768\n",
      "768\n",
      "768\n",
      "Embeddings Types:\n",
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "Embeddings Values:\n",
      "tensor([ 0.6715, -0.3474, -0.1421, -0.0567,  0.8103])\n",
      "tensor([-0.0004,  0.0014,  0.0251,  0.0272, -0.0022])\n",
      "tensor([ 0.6715, -0.3474, -0.1421, -0.0567,  0.8103])\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch sizes:\")\n",
    "print(len(sentence_embeddings1))\n",
    "print(len(sentence_embeddings2))\n",
    "print(len(sentence_embeddings3))\n",
    "\n",
    "print(\"Sequence Lengths:\")\n",
    "print(len(sentence_embeddings1[0]))\n",
    "print(len(sentence_embeddings2[0]))\n",
    "print(len(sentence_embeddings3[0]))\n",
    "\n",
    "print(\"BERT Hidden Size:\")\n",
    "print(len(sentence_embeddings1[0][0]))\n",
    "print(len(sentence_embeddings2[0][0]))\n",
    "print(len(sentence_embeddings3[0][0]))\n",
    "\n",
    "print(\"Embeddings Types:\")\n",
    "print(type(sentence_embeddings1[0][0]))\n",
    "print(type(sentence_embeddings2[0][0]))\n",
    "print(type(sentence_embeddings3[0][0]))\n",
    "\n",
    "print(\"Embeddings Values:\")\n",
    "print(torch.tensor(sentence_embeddings1[0][0][:5]))\n",
    "print(sentence_embeddings2[0][0][:5])\n",
    "print(sentence_embeddings3[0][0][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar os modelos na sentença 'Olá Mundo!', mas antes temos que preparar o input corretamente para os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'Olá Mundo!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando tamanho do vocabulário igual ao do tokenizer ou o tamanho dos embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29794\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)\n",
    "print(embeddings.embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 29794\n",
    "D_MODEL = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertendo o texto p/ token_ids (entradas das 2 redes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n",
      "tensor([  101,  1651, 22303,  3327,   106])\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(texto, \n",
    "                      return_tensors=\"pt\"\n",
    "                      ).input_ids\n",
    "\n",
    "input_ids = input_ids\n",
    "print(input_ids.shape)\n",
    "print(input_ids[0,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de documentos no dataset de treino: 8316\n",
      "Número de documentos no dataset de teste: 2079\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "train_dataset = load_dataset(\"Luciano/lener_br_text_to_lm\", \n",
    "                             split=\"train[:100%]\")  # Use 100% for a smaller dataset\n",
    "\n",
    "test_dataset = load_dataset(\"Luciano/lener_br_text_to_lm\", \n",
    "                            split=\"test[:100%]\")  # Use 100% for a smaller dataset\n",
    "\n",
    "print(\"Número de documentos no dataset de treino:\", len(train_dataset))\n",
    "print(\"Número de documentos no dataset de teste:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando quantidade de tokens por sequência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seria o mesmo que dizer que o trabalhador tem ...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O autor sustenta que a lei é formal e material...</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esse juízo decorre do fato de que o exame de c...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apesar , de o próprio responsável apresentar c...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quando de sua assunção à direção do STM , esta...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8311</th>\n",
       "      <td>No ponto , convém salientar que o Supremo Trib...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8312</th>\n",
       "      <td>Em relação ao subitem 9.2.1 , o GAP/BR informa...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8313</th>\n",
       "      <td>4 .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>O agravante limitou-se a reprisar os argumento...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315</th>\n",
       "      <td>Tem por escopo a defesa da coisa pública , bus...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8316 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  n_tokens\n",
       "0     Seria o mesmo que dizer que o trabalhador tem ...        83\n",
       "1     O autor sustenta que a lei é formal e material...       226\n",
       "2     Esse juízo decorre do fato de que o exame de c...        73\n",
       "3     Apesar , de o próprio responsável apresentar c...        24\n",
       "4     Quando de sua assunção à direção do STM , esta...        67\n",
       "...                                                 ...       ...\n",
       "8311  No ponto , convém salientar que o Supremo Trib...       154\n",
       "8312  Em relação ao subitem 9.2.1 , o GAP/BR informa...        53\n",
       "8313                                                4 .         4\n",
       "8314  O agravante limitou-se a reprisar os argumento...        42\n",
       "8315  Tem por escopo a defesa da coisa pública , bus...        24\n",
       "\n",
       "[8316 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "def input_ids_extractor(examples):\n",
    "    tokens = tokenizer(examples['text'], truncation=False, return_tensors=\"pt\")\n",
    "    return {\"input_ids\": tokens[\"input_ids\"]}\n",
    "\n",
    "df = pd.DataFrame(train_dataset)\n",
    "n_tokens = []\n",
    "for x in train_dataset.map(input_ids_extractor, remove_columns=train_dataset.column_names)[\"input_ids\"]:\n",
    "    n_tokens.append(len(x[0]))\n",
    "    counter.update(x[0])\n",
    "    \n",
    "df[\"n_tokens\"] = n_tokens\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"n_tokens\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8316.000000\n",
       "mean       48.716450\n",
       "std        53.066798\n",
       "min         2.000000\n",
       "25%        15.000000\n",
       "50%        35.000000\n",
       "75%        64.000000\n",
       "max      1009.000000\n",
       "Name: n_tokens, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"n_tokens\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listando tokens mais frequentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(117, 18875),\n",
       " (119, 17256),\n",
       " (125, 10438),\n",
       " (101, 8316),\n",
       " (102, 8316),\n",
       " (123, 6859),\n",
       " (171, 5852),\n",
       " (180, 5018),\n",
       " (118, 4854),\n",
       " (146, 4847)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50bc561c2614198a2c54bbe61ad93bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2079 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    tokens = tokenizer(examples['text'], truncation=True, padding=\"max_length\", max_length=D_MODEL, return_tensors=\"pt\")\n",
    "    return {\n",
    "        \"input_ids\": tokens[\"input_ids\"],\n",
    "        \"attention_mask\": tokens[\"attention_mask\"]\n",
    "    }\n",
    "\n",
    "train_tokenized_dataset = train_dataset.map(preprocess_function, \n",
    "                                            batched=True, \n",
    "                                            remove_columns=train_dataset.column_names)\n",
    "\n",
    "test_tokenized_dataset = test_dataset.map(preprocess_function, \n",
    "                                          batched=True, \n",
    "                                          remove_columns=test_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# está dando problema de concorrência \n",
    "NUM_WORKERS = 0 # os.cpu_count()\n",
    "\n",
    "# TODO verificar se realmente precisa disso\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(train_tokenized_dataset, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              shuffle=True, \n",
    "                              collate_fn=data_collator,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader = DataLoader(test_tokenized_dataset, \n",
    "                             batch_size=BATCH_SIZE, \n",
    "                             shuffle=True, \n",
    "                             collate_fn=data_collator,\n",
    "                             num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de batches no conjunto de treinamento: 260\n",
      "Número de batches no conjunto de testes: 65\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Número de batches no conjunto de treinamento:\", len(train_dataloader))\n",
    "print(\"Número de batches no conjunto de testes:\", len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(train_dataloader))\n",
    "print(sample_batch.keys())\n",
    "print(len(sample_batch[\"input_ids\"][0]))\n",
    "print(len(sample_batch[\"attention_mask\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bitnet.BitnetTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come será visto no resultado do summary, o BitNetTransformet já tem uma camada de embeddings incorporada na arquitetura do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type (var_name))                       Param #              Trainable\n",
       "=====================================================================================\n",
       "BitNetTransformer (BitNetTransformer)         --                   True\n",
       "├─Embedding (emb)                             3,813,632            True\n",
       "├─Transformer (transformer)                   --                   True\n",
       "│    └─ModuleList (layers)                    --                   True\n",
       "│    │    └─BitMGQA (0)                       41,472               True\n",
       "│    │    └─BitMGQA (1)                       41,472               True\n",
       "│    │    └─BitMGQA (2)                       41,472               True\n",
       "│    │    └─BitMGQA (3)                       41,472               True\n",
       "│    │    └─BitMGQA (4)                       41,472               True\n",
       "│    │    └─BitMGQA (5)                       41,472               True\n",
       "│    └─ModuleList (ffn_layers)                --                   True\n",
       "│    │    └─BitFeedForward (0)                132,736              True\n",
       "│    │    └─BitFeedForward (1)                132,736              True\n",
       "│    │    └─BitFeedForward (2)                132,736              True\n",
       "│    │    └─BitFeedForward (3)                132,736              True\n",
       "│    │    └─BitFeedForward (4)                132,736              True\n",
       "│    │    └─BitFeedForward (5)                132,736              True\n",
       "├─Sequential (to_logits)                      --                   True\n",
       "│    └─RMSNorm (0)                            128                  True\n",
       "│    └─Linear (1)                             3,843,426            True\n",
       "=====================================================================================\n",
       "Total params: 8,702,434\n",
       "Trainable params: 8,702,434\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitnet = BitNetTransformer(\n",
    "    num_tokens=VOCAB_SIZE,  # Number of unique tokens in the input\n",
    "    dim=D_MODEL,  # Dimension of the input and output embeddings\n",
    "    depth=6,  # Number of transformer layers\n",
    "    # heads=8,  # Number of attention heads\n",
    "    # ff_mult=4,  # Multiplier for the hidden dimension in the feed-forward network\n",
    ")\n",
    "\n",
    "summary(model= bitnet,\n",
    "        col_names=[\"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 29794])\n",
      "tensor([[ 0.5085, -0.6503, -1.1062,  ..., -0.1293,  0.1022, -0.5735],\n",
      "        [-0.5492,  0.5070, -0.5195,  ..., -0.5236,  0.0432, -1.0312],\n",
      "        [-0.0328,  1.2148, -1.3053,  ...,  0.7044,  0.2015,  0.0189],\n",
      "        [-0.9169,  0.5775, -0.1931,  ..., -0.9075,  0.0480, -0.7307],\n",
      "        [ 0.1907,  0.4106, -0.0051,  ...,  0.5293, -0.2727, -0.8493]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bitnet.eval()\n",
    "with torch.inference_mode():\n",
    "    bitnet_logits = bitnet(input_ids)\n",
    "\n",
    "print(bitnet_logits.shape)\n",
    "print(bitnet_logits[0,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estou usando a implementaçao da bitnet pq no torch '2.2.0+cu121' não tem implementado ainda\n",
    "from bitnet.bit_transformer import RMSNorm\n",
    "\n",
    "class BaseTransformerModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        depth: int,\n",
    "        num_tokens: int,\n",
    "        heads=8,\n",
    "        ff_mult=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, dim)\n",
    "        \n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(d_model=dim, nhead=heads),\n",
    "            num_layers=1\n",
    "        )\n",
    "\n",
    "        self.to_logits = nn.Sequential(\n",
    "            RMSNorm(dim),\n",
    "            nn.Linear(dim, num_tokens)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # embeddings sem positional encoding somados\n",
    "        x = self.emb(x)\n",
    "        x = self.decoder(tgt=x, memory=x)\n",
    "        return self.to_logits(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type (var_name))                                                Param #              Trainable\n",
       "==============================================================================================================\n",
       "BaseTransformerModel (BaseTransformerModel)                            --                   True\n",
       "├─Embedding (emb)                                                      3,813,632            True\n",
       "├─TransformerDecoder (decoder)                                         --                   True\n",
       "│    └─ModuleList (layers)                                             --                   True\n",
       "│    │    └─TransformerDecoderLayer (0)                                659,328              True\n",
       "├─Sequential (to_logits)                                               --                   True\n",
       "│    └─RMSNorm (0)                                                     128                  True\n",
       "│    └─Linear (1)                                                      3,843,426            True\n",
       "==============================================================================================================\n",
       "Total params: 8,316,514\n",
       "Trainable params: 8,316,514\n",
       "Non-trainable params: 0\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = BaseTransformerModel(\n",
    "    num_tokens=VOCAB_SIZE,  # Number of unique tokens in the input\n",
    "    dim=D_MODEL,  # Dimension of the input and output embeddings\n",
    "    depth=6,  # Number of transformer layers\n",
    "    heads=8,  # Number of attention heads\n",
    "    # ff_mult=4,  # Multiplier for the hidden dimension in the feed-forward network\n",
    "    )\n",
    "\n",
    "# c/ parâmetro input_size aloca 200MB de memória e não desaloca depois\n",
    "summary(model= baseline,\n",
    "        #input_size=(src_size, tgt_size),\n",
    "        #col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_names=[\"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 29794])\n",
      "tensor([[ 0.7746, -0.7232,  1.4470,  ..., -0.1024,  0.1412, -0.3216],\n",
      "        [ 0.3558, -0.0813, -0.7195,  ..., -0.2602,  0.6809,  0.7711],\n",
      "        [ 0.3628, -0.3117, -1.3188,  ..., -0.5278, -0.0926,  0.3631],\n",
      "        [-1.0238, -0.5662,  0.3112,  ..., -0.2797,  0.7438,  0.1896],\n",
      "        [ 0.7988,  0.2760, -0.1603,  ...,  0.5104, -0.2167,  0.0705]])\n"
     ]
    }
   ],
   "source": [
    "baseline.eval()\n",
    "with torch.inference_mode():\n",
    "    base_logits = baseline(input_ids)\n",
    "\n",
    "print(base_logits.shape)\n",
    "print(base_logits[0,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up optimizer and learning rate scheduler\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          criteria: torch.nn.functional.cross_entropy,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          epochs: int,\n",
    "          device: str = device):\n",
    "    \n",
    "    results = {\"train_loss\": [], \"test_loss\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        epoch_train_loss = 0\n",
    "        epoch_test_loss = 0\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for batch, data in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            # pode pegar as attention masks também\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids)  \n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criteria(outputs.view(-1, VOCAB_SIZE), input_ids.view(-1))\n",
    "            epoch_train_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()  \n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                # printando número de batches\n",
    "                print(f\"Batch: {batch}/{len(train_dataloader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Test loop\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for test_batch, test_data in enumerate(test_dataloader):\n",
    "                test_input_ids = test_data[\"input_ids\"].to(device)\n",
    "\n",
    "                test_outputs = model(test_input_ids)\n",
    "                test_loss = criteria(test_outputs.view(-1, VOCAB_SIZE), test_input_ids.view(-1))\n",
    "                epoch_test_loss += test_loss.item()\n",
    "                \n",
    "                if batch % 100 == 0:\n",
    "                    # printando número de batches de teste\n",
    "                    print(f\"Batch: {test_batch}/{len(test_dataloader)}, Test Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "        # printando loss após o final de uma época de treinamento        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "        results[\"train_loss\"].append(epoch_train_loss)\n",
    "        results[\"test_loss\"].append(epoch_test_loss)\n",
    "\n",
    "    return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "LEARNING_RATE = 5e-5\n",
    "DEFAULT_LOSS = torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()\n",
    "\n",
    "baseline = baseline.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0/260, Loss: 10.4627\n",
      "Batch: 100/260, Loss: 5.4199\n",
      "Batch: 200/260, Loss: 4.5337\n",
      "Epoch 1/5, Loss: 3.502687692642212\n",
      "Batch: 0/260, Loss: 3.5834\n",
      "Batch: 100/260, Loss: 2.7876\n",
      "Batch: 200/260, Loss: 2.2942\n",
      "Epoch 2/5, Loss: 2.3807220458984375\n",
      "Batch: 0/260, Loss: 2.5381\n",
      "Batch: 100/260, Loss: 1.9782\n",
      "Batch: 200/260, Loss: 2.0067\n",
      "Epoch 3/5, Loss: 2.1239449977874756\n",
      "Batch: 0/260, Loss: 2.1452\n",
      "Batch: 100/260, Loss: 1.6920\n",
      "Batch: 200/260, Loss: 1.5739\n",
      "Epoch 4/5, Loss: 1.1545331478118896\n",
      "Batch: 0/260, Loss: 1.7413\n",
      "Batch: 100/260, Loss: 1.5599\n",
      "Batch: 200/260, Loss: 1.3186\n",
      "Epoch 5/5, Loss: 1.3246814012527466\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.AdamW(baseline.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "baseline_results = train(model = baseline,\n",
    "                         train_dataloader=train_dataloader,\n",
    "                         test_dataloader=test_dataloader,\n",
    "                         criteria=DEFAULT_LOSS,\n",
    "                         optimizer=optimizer,\n",
    "                         epochs = EPOCHS,\n",
    "                         device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()\n",
    "\n",
    "bitnet = bitnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0/260, Loss: 10.6764\n",
      "Batch: 100/260, Loss: 9.8567\n",
      "Batch: 200/260, Loss: 9.0441\n",
      "Epoch 1/5, Loss: 8.476499557495117\n",
      "Batch: 0/260, Loss: 8.6132\n",
      "Batch: 100/260, Loss: 7.6309\n",
      "Batch: 200/260, Loss: 6.7194\n",
      "Epoch 2/5, Loss: 6.581727504730225\n",
      "Batch: 0/260, Loss: 6.2426\n",
      "Batch: 100/260, Loss: 5.6193\n",
      "Batch: 200/260, Loss: 4.9835\n",
      "Epoch 3/5, Loss: 4.457399845123291\n",
      "Batch: 0/260, Loss: 4.5872\n",
      "Batch: 100/260, Loss: 3.3761\n",
      "Batch: 200/260, Loss: 2.9851\n",
      "Epoch 4/5, Loss: 2.79992938041687\n",
      "Batch: 0/260, Loss: 3.2453\n",
      "Batch: 100/260, Loss: 2.2316\n",
      "Batch: 200/260, Loss: 2.0965\n",
      "Epoch 5/5, Loss: 2.43396258354187\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(bitnet.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "bitnet_results = train(model = bitnet,\n",
    "                       train_dataloader = train_dataloader,\n",
    "                       test_dataloader = test_dataloader,\n",
    "                       criteria = DEFAULT_LOSS,\n",
    "                       optimizer = optimizer,\n",
    "                       epochs = EPOCHS,\n",
    "                       device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "torch.save(baseline, \"./models/baseline_transformer.pt\")\n",
    "\n",
    "torch.save(bitnet, \"./models/bitnet_transformer.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def generate_text(model, tokenizer, prompt, max_length=50, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generates text using an autoregressive approach with a Transformer model.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The autoregressive Transformer model.\n",
    "        tokenizer (AutoTokenizer): The tokenizer for encoding and decoding text.\n",
    "        prompt (str): The initial text prompt to start the generation.\n",
    "        max_length (int): Maximum length of the generated text.\n",
    "        temperature (float): Temperature value for sampling (higher = more randomness).\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated text.\n",
    "    \"\"\"\n",
    "    # Encode the input prompt into token IDs\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "\n",
    "    # Move input_ids to the same device as the model (CPU/GPU)\n",
    "    input_ids = input_ids.to(next(model.parameters()).device)\n",
    "\n",
    "    # Initialize a list to store generated tokens\n",
    "    generated_ids = input_ids.clone()\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Use a loop to generate tokens one by one\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            # Get the model's logits for the next token\n",
    "            output = model(generated_ids)\n",
    "\n",
    "            logits = output[:, -1, :]  # Take the logits of the last token\n",
    "\n",
    "            # Apply temperature scaling to logits if temperature is specified\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Use softmax to get probabilities and sample the next token id\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            next_token_id = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            # Append the predicted token id to the generated_ids\n",
    "            generated_ids = torch.cat([generated_ids, next_token_id], dim=-1)\n",
    "\n",
    "            # If the model generates the EOS (end-of-sequence) token, stop early\n",
    "            if next_token_id.item() == tokenizer.eos_token_id:\n",
    "                break\n",
    "\n",
    "    # Decode the generated token IDs back into a string\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O autor sustenta que a lei é formalRei reque atua tentadocrimin Fox mostrada honra។ Hend sustentação Federal運ensteinansãoíticos lavagem mecânicoíficos\n",
      "O autor sustenta que a lei é formal\n"
     ]
    }
   ],
   "source": [
    "# Example prompt and text generation\n",
    "prompt = \"O autor sustenta que a lei é formal\"\n",
    "\n",
    "bitnet_generated_text = generate_text(model=bitnet, \n",
    "                               tokenizer=tokenizer, \n",
    "                               prompt=prompt, \n",
    "                               max_length=20, \n",
    "                               temperature=0.8)\n",
    "\n",
    "\n",
    "baseline_generated_text = generate_text(model=baseline, \n",
    "                               tokenizer=tokenizer, \n",
    "                               prompt=prompt, \n",
    "                               max_length=20, \n",
    "                               temperature=0.8)\n",
    "\n",
    "\n",
    "print(bitnet_generated_text)\n",
    "print(baseline_generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = baseline.to(\"cpu\")\n",
    "bitnet = bitnet.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando modelos salvos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_baseline = torch.load(\"./models/baseline_transformer.pt\", \n",
    "                             weights_only=False)\n",
    "\n",
    "loaded_bitnet = torch.load(\"./models/bitnet_transformer.pt\", \n",
    "                           weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O autor sustenta que a lei é formal Wild Sele inic significadoteriores♯ nos passageirosntimento atos curiosidadeificadoreuro Pack恩스螂 igrejas incorpora fam\n",
      "O autor sustenta que a lei é formal\n"
     ]
    }
   ],
   "source": [
    "baseline_generated_text = generate_text(model=loaded_baseline, \n",
    "                               tokenizer=tokenizer, \n",
    "                               prompt=prompt, \n",
    "                               max_length=20, \n",
    "                               temperature=0.8)\n",
    "\n",
    "bitnet_generated_text = generate_text(model=loaded_bitnet, \n",
    "                               tokenizer=tokenizer, \n",
    "                               prompt=prompt, \n",
    "                               max_length=20, \n",
    "                               temperature=0.8)\n",
    "\n",
    "print(bitnet_generated_text)\n",
    "print(baseline_generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitnet2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
