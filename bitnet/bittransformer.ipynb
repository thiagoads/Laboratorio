{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BitNetTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from bitnet import BitNetTransformer\n",
    "\n",
    "from app.utils import clear_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bertimbau Tokenizer & Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "huggingface_model = \"neuralmind/bert-base-portuguese-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(huggingface_model)\n",
    "model = AutoModel.from_pretrained(huggingface_model)\n",
    "feature_extractor = pipeline('feature-extraction', model=model, tokenizer=tokenizer)\n",
    "embeddings = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29794\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)\n",
    "print(embeddings.embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando diferentes maneiras de transformar texto para embbedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'O advogado apresentou recurso para o ju√≠z'\n",
    "\n",
    "# a. contextualized embeddings c/ feature_extractor: texto tokenizado automaticamente, passa para embedding, encoder e attention layers antes\n",
    "sentence_embeddings1 = feature_extractor(sentence)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    sentence_tokenized = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    sentence_input_ids = sentence_tokenized[\"input_ids\"]\n",
    "    sentence_attention_mask = sentence_tokenized[\"attention_mask\"]\n",
    "\n",
    "    # b. non-contextualized embeddings com embedding layer do bertimbau: usa embbeding layer \n",
    "    # antes de passar na rede transformer, ou seja, sem passar pelo encoder e attention layers\n",
    "    sentence_embeddings2 = embeddings(sentence_input_ids)\n",
    "\n",
    "    # c. a mesma coisa da primeira abordagem s√≥ que mais explicita, sem as facilidades do pipeline\n",
    "    sentence_embeddings3 = model(input_ids=sentence_input_ids, \n",
    "                                attention_mask=sentence_attention_mask\n",
    "                                ).last_hidden_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch sizes:\n",
      "1\n",
      "1\n",
      "1\n",
      "Sequence Lengths:\n",
      "10\n",
      "10\n",
      "10\n",
      "BERT Hidden Size:\n",
      "768\n",
      "768\n",
      "768\n",
      "Embeddings Types:\n",
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "Embeddings Values:\n",
      "tensor([ 0.6715, -0.3474, -0.1421, -0.0567,  0.8103])\n",
      "tensor([-0.0004,  0.0014,  0.0251,  0.0272, -0.0022])\n",
      "tensor([ 0.6715, -0.3474, -0.1421, -0.0567,  0.8103])\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch sizes:\")\n",
    "print(len(sentence_embeddings1))\n",
    "print(len(sentence_embeddings2))\n",
    "print(len(sentence_embeddings3))\n",
    "\n",
    "print(\"Sequence Lengths:\")\n",
    "print(len(sentence_embeddings1[0]))\n",
    "print(len(sentence_embeddings2[0]))\n",
    "print(len(sentence_embeddings3[0]))\n",
    "\n",
    "print(\"BERT Hidden Size:\")\n",
    "print(len(sentence_embeddings1[0][0]))\n",
    "print(len(sentence_embeddings2[0][0]))\n",
    "print(len(sentence_embeddings3[0][0]))\n",
    "\n",
    "print(\"Embeddings Types:\")\n",
    "print(type(sentence_embeddings1[0][0]))\n",
    "print(type(sentence_embeddings2[0][0]))\n",
    "print(type(sentence_embeddings3[0][0]))\n",
    "\n",
    "print(\"Embeddings Values:\")\n",
    "print(torch.tensor(sentence_embeddings1[0][0][:5]))\n",
    "print(sentence_embeddings2[0][0][:5])\n",
    "print(sentence_embeddings3[0][0][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar os modelos na senten√ßa 'Ol√° Mundo!', mas antes temos que preparar o input corretamente para os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Ol√° Mundo!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando tamanho do vocabul√°rio igual ao do tokenizer ou o tamanho dos embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29794\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)\n",
    "print(embeddings.embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 29794\n",
    "D_MODEL = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertendo o texto p/ token_ids (entradas das 2 redes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n",
      "tensor([  101,  1651, 22303,  3327,   106])\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "print(input_ids.shape)\n",
    "print(input_ids[0,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# tokens = [\"eu\", \"voc√™\", \"ele\", \"ela\", \"n√≥s\", \"v√≥s\", \"eles\", \"elas\", \"meu\", \"minha\", \n",
    "#  \"meus\", \"minhas\", \"teu\", \"tua\", \"teus\", \"tuas\", \"seu\", \"sua\", \"seus\", \"suas\",\n",
    "#  \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"vosso\", \"vossa\", \"vossos\", \"vossas\",\n",
    "#  \"este\", \"esta\", \"estes\", \"estas\", \"esse\", \"essa\", \"esses\", \"essas\", \n",
    "#  \"aquele\", \"aquela\", \"aqueles\", \"aquelas\", \"o\", \"a\", \"os\", \"as\", \"um\", \n",
    "#  \"uma\", \"uns\", \"umas\", \"de\", \"do\", \"da\", \"dos\", \"das\", \"em\", \"no\", \"na\", \n",
    "#  \"nos\", \"nas\", \"por\", \"para\", \"com\", \"sem\", \"sobre\", \"entre\", \"mas\", \"ou\", \n",
    "#  \"e\", \"tamb√©m\", \"como\", \"porque\", \"quando\", \"onde\", \"at√©\", \"se\", \"n√£o\", \n",
    "#  \"sim\", \"muito\", \"pouco\", \"mais\", \"menos\", \"j√°\", \"ainda\", \"s√≥\", \"tudo\", \n",
    "#  \"nada\", \"algo\", \"algu√©m\", \"ningu√©m\", \"algum\", \"nenhum\", \"todo\", \"qualquer\", \n",
    "#  \"cada\", \"mesmo\", \"outro\", \"primeiro\", \"segundo\", \"antes\", \"depois\", \"agora\", \n",
    "#  \"ent√£o\", \"hoje\", \"ontem\", \"amanh√£\", \"sempre\", \"nunca\", \"quase\", \"bem\", \n",
    "#  \"mal\", \"muito\", \"tanto\", \"pouco\", \"bastante\", \"todo\", \"bom\", \"ruim\", \n",
    "#  \"grande\", \"pequeno\", \"novo\", \"velho\", \"f√°cil\", \"dif√≠cil\", \"importante\",\n",
    "#  \"saber\", \"fazer\", \"dizer\", \"poder\", \"querer\", \"ver\", \"dar\", \"estar\", \n",
    "#  \"ter\", \"vir\", \"ir\", \"ficar\", \"parecer\", \"achar\", \"precisar\", \"gostar\",\n",
    "#  \"come√ßar\", \"tentar\", \"passar\", \"entender\", \"voltar\", \"deixar\", \"encontrar\"]\n",
    "\n",
    "# token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "# token_embeddings = embeddings(torch.tensor(token_ids)).detach().cpu().numpy()\n",
    "\n",
    "# pca = PCA(n_components=2)\n",
    "# tsne = TSNE(n_components=2, perplexity=30, random_state=0)\n",
    "# token_embeddings_2d = tsne.fit_transform(token_embeddings)\n",
    "\n",
    "# plt.scatter(token_embeddings_2d[:,0], token_embeddings_2d[:, 1])\n",
    "\n",
    "# tokens_to_show = [\"ele\", \"ela\", \"hoje\", \"ontem\", \"amanh√£\", \"sempre\", \"nunca\", \"novo\", \"velho\"]\n",
    "\n",
    "# for token in tokens_to_show:\n",
    "#     i = tokens.index(token)\n",
    "#     plt.annotate(token, (token_embeddings_2d[i,0], token_embeddings_2d[i, 1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de documentos no dataset de treino: 8316\n",
      "N√∫mero de documentos no dataset de teste: 2079\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "huggingface_dataset = \"Luciano/lener_br_text_to_lm\"\n",
    "#huggingface_dataset = \"eduagarcia/LegalPT_dedup\"\n",
    "huggingface_subset = None\n",
    "\n",
    "# Use % for a smaller dataset\n",
    "train_dataset = load_dataset(huggingface_dataset, \n",
    "                             huggingface_subset,\n",
    "                             split=\"train[:100%]\")\n",
    "\n",
    "# Use % for a smaller dataset\n",
    "test_dataset = load_dataset(huggingface_dataset, \n",
    "                            huggingface_subset,\n",
    "                            split=\"test[:100%]\")\n",
    "\n",
    "print(\"N√∫mero de documentos no dataset de treino:\", len(train_dataset))\n",
    "print(\"N√∫mero de documentos no dataset de teste:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando quantidade de tokens por sequ√™ncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seria o mesmo que dizer que o trabalhador tem ...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O autor sustenta que a lei √© formal e material...</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esse ju√≠zo decorre do fato de que o exame de c...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apesar , de o pr√≥prio respons√°vel apresentar c...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quando de sua assun√ß√£o √† dire√ß√£o do STM , esta...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8311</th>\n",
       "      <td>No ponto , conv√©m salientar que o Supremo Trib...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8312</th>\n",
       "      <td>Em rela√ß√£o ao subitem 9.2.1 , o GAP/BR informa...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8313</th>\n",
       "      <td>4 .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>O agravante limitou-se a reprisar os argumento...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315</th>\n",
       "      <td>Tem por escopo a defesa da coisa p√∫blica , bus...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8316 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  n_tokens\n",
       "0     Seria o mesmo que dizer que o trabalhador tem ...        83\n",
       "1     O autor sustenta que a lei √© formal e material...       226\n",
       "2     Esse ju√≠zo decorre do fato de que o exame de c...        73\n",
       "3     Apesar , de o pr√≥prio respons√°vel apresentar c...        24\n",
       "4     Quando de sua assun√ß√£o √† dire√ß√£o do STM , esta...        67\n",
       "...                                                 ...       ...\n",
       "8311  No ponto , conv√©m salientar que o Supremo Trib...       154\n",
       "8312  Em rela√ß√£o ao subitem 9.2.1 , o GAP/BR informa...        53\n",
       "8313                                                4 .         4\n",
       "8314  O agravante limitou-se a reprisar os argumento...        42\n",
       "8315  Tem por escopo a defesa da coisa p√∫blica , bus...        24\n",
       "\n",
       "[8316 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "def input_ids_extractor(examples):\n",
    "    tokens = tokenizer(examples['text'], \n",
    "                       truncation=False, \n",
    "                       return_tensors=\"pt\")\n",
    "    \n",
    "    return {\"input_ids\": tokens[\"input_ids\"]}\n",
    "\n",
    "df = pd.DataFrame(train_dataset)\n",
    "n_tokens = []\n",
    "for x in train_dataset.map(input_ids_extractor, remove_columns=train_dataset.column_names)[\"input_ids\"]:\n",
    "    n_tokens.append(len(x[0]))\n",
    "    counter.update(x[0])\n",
    "    \n",
    "df[\"n_tokens\"] = n_tokens\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"n_tokens\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8316.000000\n",
       "mean       48.716450\n",
       "std        53.066798\n",
       "min         2.000000\n",
       "25%        15.000000\n",
       "50%        35.000000\n",
       "75%        64.000000\n",
       "max      1009.000000\n",
       "Name: n_tokens, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"n_tokens\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listando tokens mais frequentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(117, 18875),\n",
       " (119, 17256),\n",
       " (125, 10438),\n",
       " (101, 8316),\n",
       " (102, 8316),\n",
       " (123, 6859),\n",
       " (171, 5852),\n",
       " (180, 5018),\n",
       " (118, 4854),\n",
       " (146, 4847),\n",
       " (120, 4319),\n",
       " (122, 4252),\n",
       " (179, 4245),\n",
       " (22281, 2949),\n",
       " (173, 2613),\n",
       " (114, 2306),\n",
       " (22301, 2265),\n",
       " (113, 2164),\n",
       " (176, 2133),\n",
       " (131, 1974)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 106), ('\"', 107), ('#', 108), ('##!', 12091), ('##!\"', 8678), ('##!,', 19684), ('##\"', 206), ('##\"\"', 2474), ('##\"(', 11447), ('##\")', 1663), ('##\",', 355), ('##\"-', 18837), ('##\".', 435), ('##\":', 6210), ('##\";', 4702), ('##\">', 11428), ('##\"‚Äù', 22172), ('###', 5104), ('##$', 6300), ('##%', 16658), ('##%,', 21099), ('##%.', 11519), ('##&', 2808), (\"##'\", 2469), (\"##',\", 8381), (\"##'.\", 11111), ('##(', 242), ('##(\"', 20530), ('##)', 5071), ('##)\"', 8134), ('##),', 396), ('##).', 480), ('##):', 6460), ('##);', 3238), ('##*', 19329), ('##+', 7017), ('##,', 1122), ('##,\"', 6385), ('##-', 571), ('##--', 20219), ('##-0', 5431), ('##-1', 1231), ('##-2', 2558), ('##-3', 5797), ('##-4', 6782), ('##-5', 8683), ('##-6', 11576), ('##-7', 9827), ('##-8', 9443), ('##-9', 8836)]\n",
      "[('„Ää', 1888), ('„Äã', 1889), ('„Äå', 1890), ('„Äç', 1891), ('„Äé', 1892), ('„Äè', 1893), ('„Äê', 1894), ('„Äë', 1895), ('„Äî', 1897), ('„Äï', 1898), ('„Äñ', 1899), ('„Äó', 1900), ('„Äú', 1901), ('„Äù', 1902), ('„Éª', 2068), ('Ô¥æ', 10037), ('Ô¥ø', 10038), ('Ô∏∞', 10041), ('Ôπê', 10042), ('Ôπë', 10043), ('Ôπî', 10044), ('Ôπï', 10045), ('Ôπù', 10046), ('Ôπû', 10047), ('Ôπ£', 10048), ('ÔºÅ', 10055), ('ÔºÇ', 10056), ('ÔºÉ', 10057), ('ÔºÖ', 10058), ('ÔºÜ', 10059), ('Ôºà', 10060), ('Ôºâ', 10061), ('Ôºä', 10062), ('Ôºå', 10064), ('Ôºç', 10065), ('Ôºé', 10066), ('Ôºè', 10067), ('Ôºö', 10078), ('Ôºõ', 10079), ('Ôºü', 10083), ('Ôº†', 10084), ('Ôºª', 10091), ('Ôºº', 10092), ('ÔºΩ', 10093), ('Ôºø', 10094), ('ÔΩ°', 10097), ('ÔΩ¢', 10098), ('ÔΩ£', 10099), ('ÔΩ§', 10100), ('ÔΩ•', 10101)]\n",
      "[('[PAD]', 0), ('[unused1]', 1), ('[unused2]', 2), ('[unused3]', 3), ('[unused4]', 4), ('[unused5]', 5), ('[unused6]', 6), ('[unused7]', 7), ('[unused8]', 8), ('[unused9]', 9), ('[unused10]', 10), ('[unused11]', 11), ('[unused12]', 12), ('[unused13]', 13), ('[unused14]', 14), ('[unused15]', 15), ('[unused16]', 16), ('[unused17]', 17), ('[unused18]', 18), ('[unused19]', 19), ('[unused20]', 20), ('[unused21]', 21), ('[unused22]', 22), ('[unused23]', 23), ('[unused24]', 24), ('[unused25]', 25), ('[unused26]', 26), ('[unused27]', 27), ('[unused28]', 28), ('[unused29]', 29), ('[unused30]', 30), ('[unused31]', 31), ('[unused32]', 32), ('[unused33]', 33), ('[unused34]', 34), ('[unused35]', 35), ('[unused36]', 36), ('[unused37]', 37), ('[unused38]', 38), ('[unused39]', 39), ('[unused40]', 40), ('[unused41]', 41), ('[unused42]', 42), ('[unused43]', 43), ('[unused44]', 44), ('[unused45]', 45), ('[unused46]', 46), ('[unused47]', 47), ('[unused48]', 48), ('[unused49]', 49)]\n",
      "[('##Ìúæ', 29744), ('##Ìúø', 29745), ('##ÌùÄ', 29746), ('##ÌùÅ', 29747), ('##ÌùÇ', 29748), ('##ÌùÉ', 29749), ('##ÌùÑ', 29750), ('##ÌùÖ', 29751), ('##ÌùÜ', 29752), ('##Ìùá', 29753), ('##Ìùà', 29754), ('##Ìùâ', 29755), ('##Ìùä', 29756), ('##Ìùã', 29757), ('##Ìùå', 29758), ('##Ìùç', 29759), ('##Ìùé', 29760), ('##Ìùè', 29761), ('##Ìù≠', 29762), ('##ÌùÆ', 29763), ('##ÌùØ', 29764), ('##Ìù∞', 29765), ('##Ìù±', 29766), ('##Ìù≤', 29767), ('##Ìù≥', 29768), ('##Ìù¥', 29769), ('##Ìùµ', 29770), ('##Ìù∂', 29771), ('##Ìù∑', 29772), ('##Ìù∏', 29773), ('##Ìùπ', 29774), ('##Ìù∫', 29775), ('##Ìùª', 29776), ('##Ìùº', 29777), ('##ÌùΩ', 29778), ('##Ìùæ', 29779), ('##Ìùø', 29780), ('##ÌûÄ', 29781), ('##ÌûÅ', 29782), ('##ÌûÇ', 29783), ('##ÌûÉ', 29784), ('##ÌûÑ', 29785), ('##ÌûÖ', 29786), ('##ÌûÜ', 29787), ('##Ìûá', 29788), ('##Ìûô', 29789), ('##Ô®î', 29790), ('##êéæ', 29791), ('##ê¨û', 29792), ('##ê¨≠', 29793)]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "print(sorted(tokenizer.vocab.items(), key=operator.itemgetter(0))[0:50])\n",
    "print(sorted(tokenizer.vocab.items(), key=operator.itemgetter(0))[-50:])\n",
    "print(sorted(tokenizer.vocab.items(), key=operator.itemgetter(1))[0:50])\n",
    "print(sorted(tokenizer.vocab.items(), key=operator.itemgetter(1))[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117, 119, 125, 101, 102, 123, 171, 180, 118, 146, 120, 122, 179, 22281, 173, 114, 22301, 113, 176, 131]\n",
      ",. de [CLS] [SEP] a do da - o / e ques em )A ( se :\n"
     ]
    }
   ],
   "source": [
    "most_common_tokens = [x[0] for x in counter.most_common(20)]\n",
    "print(most_common_tokens)\n",
    "print(tokenizer.decode(most_common_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    tokens = tokenizer(examples['text'], truncation=True, padding=\"max_length\", max_length=D_MODEL, return_tensors=\"pt\")\n",
    "    return {\n",
    "        \"input_ids\": tokens[\"input_ids\"],\n",
    "        \"attention_mask\": tokens[\"attention_mask\"]\n",
    "    }\n",
    "\n",
    "train_tokenized_dataset = train_dataset.map(preprocess_function, \n",
    "                                            batched=True, \n",
    "                                            remove_columns=train_dataset.column_names)\n",
    "\n",
    "test_tokenized_dataset = test_dataset.map(preprocess_function, \n",
    "                                          batched=True, \n",
    "                                          remove_columns=test_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# est√° dando problema de concorr√™ncia \n",
    "NUM_WORKERS = 0 # os.cpu_count()\n",
    "\n",
    "# TODO verificar se realmente precisa disso\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(train_tokenized_dataset, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              shuffle=True, \n",
    "                              collate_fn=data_collator,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader = DataLoader(test_tokenized_dataset, \n",
    "                             batch_size=BATCH_SIZE, \n",
    "                             shuffle=True, \n",
    "                             collate_fn=data_collator,\n",
    "                             num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de batches no conjunto de treinamento: 260\n",
      "N√∫mero de batches no conjunto de testes: 65\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"N√∫mero de batches no conjunto de treinamento:\", len(train_dataloader))\n",
    "print(\"N√∫mero de batches no conjunto de testes:\", len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(train_dataloader))\n",
    "print(sample_batch.keys())\n",
    "print(len(sample_batch[\"input_ids\"][0]))\n",
    "print(len(sample_batch[\"attention_mask\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bitnet.BitnetTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come ser√° visto no resultado do summary, o BitNetTransformet j√° tem uma camada de embeddings incorporada na arquitetura do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type (var_name))                       Param #              Trainable\n",
       "=====================================================================================\n",
       "BitNetTransformer (BitNetTransformer)         --                   True\n",
       "‚îú‚îÄEmbedding (emb)                             3,813,632            True\n",
       "‚îú‚îÄTransformer (transformer)                   --                   True\n",
       "‚îÇ    ‚îî‚îÄModuleList (layers)                    --                   True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBitMGQA (0)                       41,472               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBitMGQA (1)                       41,472               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBitMGQA (2)                       41,472               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBitMGQA (3)                       41,472               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBitMGQA (4)                       41,472               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBitMGQA (5)                       41,472               True\n",
       "‚îÇ    ‚îî‚îÄModuleList (ffn_layers)                --                   True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBitFeedForward (0)                132,736              True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBitFeedForward (1)                132,736              True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBitFeedForward (2)                132,736              True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBitFeedForward (3)                132,736              True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBitFeedForward (4)                132,736              True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBitFeedForward (5)                132,736              True\n",
       "‚îú‚îÄSequential (to_logits)                      --                   True\n",
       "‚îÇ    ‚îî‚îÄRMSNorm (0)                            128                  True\n",
       "‚îÇ    ‚îî‚îÄLinear (1)                             3,843,426            True\n",
       "=====================================================================================\n",
       "Total params: 8,702,434\n",
       "Trainable params: 8,702,434\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitnet = BitNetTransformer(\n",
    "    num_tokens=VOCAB_SIZE,  # Number of unique tokens in the input\n",
    "    dim=D_MODEL,  # Dimension of the input and output embeddings\n",
    "    depth=6,  # Number of transformer layers\n",
    "    # heads=8,  # Number of attention heads\n",
    "    # ff_mult=4,  # Multiplier for the hidden dimension in the feed-forward network\n",
    ")\n",
    "\n",
    "summary(model= bitnet,\n",
    "        col_names=[\"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"],\n",
    "        depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 29794])\n",
      "tensor([[-6.6770e-01,  8.7659e-01, -6.5567e-01,  ..., -5.4037e-01,\n",
      "         -2.9231e-01,  6.0843e-01],\n",
      "        [ 8.7974e-01,  9.0023e-01, -9.4397e-02,  ..., -4.9147e-01,\n",
      "          2.7608e-02, -5.5653e-01],\n",
      "        [ 8.3096e-01,  6.1559e-04, -8.0338e-01,  ..., -5.5055e-01,\n",
      "         -8.9815e-02, -7.4897e-01],\n",
      "        [ 5.2664e-01, -4.1990e-01,  2.4366e-01,  ..., -3.0699e-01,\n",
      "          1.6221e-01, -9.1278e-01],\n",
      "        [ 2.0465e+00,  3.6109e-02,  7.7685e-01,  ..., -8.7854e-02,\n",
      "         -2.6157e-01, -4.3809e-01]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bitnet.eval()\n",
    "with torch.inference_mode():\n",
    "    bitnet_logits = bitnet(input_ids)\n",
    "\n",
    "print(bitnet_logits.shape)\n",
    "print(bitnet_logits[0,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estou usando a implementa√ßao da bitnet pq no torch '2.2.0+cu121' n√£o tem implementado ainda\n",
    "from bitnet.bit_transformer import RMSNorm\n",
    "\n",
    "class BaseTransformerModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        depth: int,\n",
    "        num_tokens: int,\n",
    "        heads: int=8,\n",
    "        ff_mult=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, dim)\n",
    "        \n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(d_model=dim, \n",
    "                                       nhead=heads, \n",
    "                                       batch_first=True),\n",
    "            num_layers=depth\n",
    "        )\n",
    "\n",
    "        self.to_logits = nn.Sequential(\n",
    "            RMSNorm(dim),\n",
    "            nn.Linear(dim, num_tokens)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # embeddings sem positional encoding somados\n",
    "        x = self.emb(x)\n",
    "        x = self.decoder(tgt=x, memory=x)\n",
    "        return self.to_logits(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type (var_name))                                                Param #              Trainable\n",
       "==============================================================================================================\n",
       "BaseTransformerModel (BaseTransformerModel)                            --                   True\n",
       "‚îú‚îÄEmbedding (emb)                                                      3,813,632            True\n",
       "‚îú‚îÄTransformerDecoder (decoder)                                         --                   True\n",
       "‚îÇ    ‚îî‚îÄModuleList (layers)                                             --                   True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerDecoderLayer (0)                                659,328              True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerDecoderLayer (1)                                659,328              True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerDecoderLayer (2)                                659,328              True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerDecoderLayer (3)                                659,328              True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerDecoderLayer (4)                                659,328              True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerDecoderLayer (5)                                659,328              True\n",
       "‚îú‚îÄSequential (to_logits)                                               --                   True\n",
       "‚îÇ    ‚îî‚îÄRMSNorm (0)                                                     128                  True\n",
       "‚îÇ    ‚îî‚îÄLinear (1)                                                      3,843,426            True\n",
       "==============================================================================================================\n",
       "Total params: 11,613,154\n",
       "Trainable params: 11,613,154\n",
       "Non-trainable params: 0\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = BaseTransformerModel(\n",
    "    num_tokens=VOCAB_SIZE,  # Number of unique tokens in the input\n",
    "    dim=D_MODEL,  # Dimension of the input and output embeddings\n",
    "    depth=6,  # Number of transformer layers\n",
    "    heads=8,  # Number of attention heads\n",
    "    # ff_mult=4,  # Multiplier for the hidden dimension in the feed-forward network\n",
    "    )\n",
    "\n",
    "# c/ par√¢metro input_size aloca 200MB de mem√≥ria e n√£o desaloca depois\n",
    "summary(model= baseline,\n",
    "        #input_size=(src_size, tgt_size),\n",
    "        #col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_names=[\"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"],\n",
    "        depth=3\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 29794])\n",
      "tensor([[ 0.5391,  0.9492, -0.2469,  ...,  0.8088,  0.2139, -0.2902],\n",
      "        [-0.4438,  0.7119, -0.2255,  ...,  0.8506, -0.7504,  0.1982],\n",
      "        [-0.1110, -0.3671, -0.0774,  ..., -0.1292, -0.0017,  0.4343],\n",
      "        [ 0.5665,  0.6170,  0.5359,  ...,  0.2547, -0.7920,  0.5707],\n",
      "        [-0.2717,  0.2186, -0.6908,  ..., -0.4314, -1.0345,  0.9620]])\n"
     ]
    }
   ],
   "source": [
    "baseline.eval()\n",
    "with torch.inference_mode():\n",
    "    base_logits = baseline(input_ids)\n",
    "\n",
    "print(base_logits.shape)\n",
    "print(base_logits[0,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          criteria: torch.nn.functional.cross_entropy,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          epochs: int,\n",
    "          device: str = device,\n",
    "          interval: int = 100):\n",
    "    \n",
    "    results = {\"train_loss\": [], \"test_loss\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(f\"Epoch: {epoch}/{epochs}\")\n",
    "\n",
    "        epoch_train_loss = 0\n",
    "        epoch_test_loss = 0\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        \n",
    "        for batch, data in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            # pode pegar as attention masks tamb√©m\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids)  \n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criteria(outputs.view(-1, VOCAB_SIZE), input_ids.view(-1))\n",
    "            epoch_train_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()  \n",
    "\n",
    "            if batch % interval == 0:\n",
    "                # printando n√∫mero de batches\n",
    "                print(f\" -> Batch: {batch}/{len(train_dataloader)}, Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Test loop\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for test_batch, test_data in enumerate(test_dataloader):\n",
    "                test_input_ids = test_data[\"input_ids\"].to(device)\n",
    "\n",
    "                test_outputs = model(test_input_ids)\n",
    "                test_loss = criteria(test_outputs.view(-1, VOCAB_SIZE), test_input_ids.view(-1))\n",
    "                epoch_test_loss += test_loss.item()\n",
    "                \n",
    "                if batch % interval == 0:\n",
    "                    # printando n√∫mero de batches de teste\n",
    "                    print(f\" -> Batch: {test_batch}/{len(test_dataloader)}, Test Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "        epoch_train_loss = epoch_train_loss / len(train_dataloader)\n",
    "        epoch_test_loss = epoch_test_loss / len(test_dataloader)\n",
    "\n",
    "        # printando loss ap√≥s o final de uma √©poca de treinamento        \n",
    "        print(f\" = Train Loss: {epoch_train_loss}, Test Loss: {epoch_test_loss}\")\n",
    "\n",
    "\n",
    "        results[\"train_loss\"].append(epoch_train_loss)\n",
    "        results[\"test_loss\"].append(epoch_test_loss)\n",
    "\n",
    "    return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "LEARNING_RATE = 5e-5\n",
    "DEFAULT_LOSS = torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "clear_memory()\n",
    "\n",
    "baseline = baseline.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/5\n",
      " -> Batch: 0/260, Train Loss: 10.2195\n",
      " -> Batch: 100/260, Train Loss: 5.1703\n",
      " -> Batch: 200/260, Train Loss: 3.8195\n",
      " = Train Loss: 4.861468277527735, Test Loss: 3.2316161669217625\n",
      "Epoch: 1/5\n",
      " -> Batch: 0/260, Train Loss: 3.4532\n",
      " -> Batch: 100/260, Train Loss: 2.5085\n",
      " -> Batch: 200/260, Train Loss: 2.3974\n",
      " = Train Loss: 2.604790538090926, Test Loss: 1.934318940456097\n",
      "Epoch: 2/5\n",
      " -> Batch: 0/260, Train Loss: 2.0894\n",
      " -> Batch: 100/260, Train Loss: 1.9642\n",
      " -> Batch: 200/260, Train Loss: 1.5358\n",
      " = Train Loss: 1.7289463808903327, Test Loss: 1.3897585016030531\n",
      "Epoch: 3/5\n",
      " -> Batch: 0/260, Train Loss: 1.9217\n",
      " -> Batch: 100/260, Train Loss: 1.3056\n",
      " -> Batch: 200/260, Train Loss: 1.0252\n",
      " = Train Loss: 1.3042342504629723, Test Loss: 1.0804680530841535\n",
      "Epoch: 4/5\n",
      " -> Batch: 0/260, Train Loss: 1.2918\n",
      " -> Batch: 100/260, Train Loss: 1.1409\n",
      " -> Batch: 200/260, Train Loss: 0.8464\n",
      " = Train Loss: 1.040754289810474, Test Loss: 0.8754633587140304\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.AdamW(baseline.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "baseline_results = train(model = baseline,\n",
    "                         train_dataloader=train_dataloader,\n",
    "                         test_dataloader=test_dataloader,\n",
    "                         criteria=DEFAULT_LOSS,\n",
    "                         optimizer=optimizer,\n",
    "                         epochs = EPOCHS,\n",
    "                         device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()\n",
    "\n",
    "bitnet = bitnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/5\n",
      " -> Batch: 0/260, Train Loss: 10.0865\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: the launch timed out and was terminated\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(bitnet\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE)\n\u001b[0;32m----> 3\u001b[0m bitnet_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbitnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcriteria\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDEFAULT_LOSS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, criteria, optimizer, epochs, device, interval)\u001b[0m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# pode pegar as attention masks tamb√©m\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     28\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids)  \n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: the launch timed out and was terminated\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(bitnet.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "bitnet_results = train(model = bitnet,\n",
    "                       train_dataloader = train_dataloader,\n",
    "                       test_dataloader = test_dataloader,\n",
    "                       criteria = DEFAULT_LOSS,\n",
    "                       optimizer = optimizer,\n",
    "                       epochs = EPOCHS,\n",
    "                       device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "torch.save(baseline, \"./models/baseline_transformer.pt\")\n",
    "\n",
    "torch.save(bitnet, \"./models/bitnet_transformer.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gera√ß√£o de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def generate_text(model, tokenizer, prompt, max_length=50, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generates text using an autoregressive approach with a Transformer model.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The autoregressive Transformer model.\n",
    "        tokenizer (AutoTokenizer): The tokenizer for encoding and decoding text.\n",
    "        prompt (str): The initial text prompt to start the generation.\n",
    "        max_length (int): Maximum length of the generated text.\n",
    "        temperature (float): Temperature value for sampling (higher = more randomness).\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated text.\n",
    "    \"\"\"\n",
    "    # Encode the input prompt into token IDs\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "\n",
    "    # Move input_ids to the same device as the model (CPU/GPU)\n",
    "    input_ids = input_ids.to(next(model.parameters()).device)\n",
    "\n",
    "    # Initialize a list to store generated tokens\n",
    "    generated_ids = input_ids.clone()\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Use a loop to generate tokens one by one\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            # Get the model's logits for the next token\n",
    "            output = model(generated_ids)\n",
    "\n",
    "            logits = output[:, -1, :]  # Take the logits of the last token\n",
    "\n",
    "            # Apply temperature scaling to logits if temperature is specified\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Use softmax to get probabilities and sample the next token id\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            next_token_id = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            # Append the predicted token id to the generated_ids\n",
    "            generated_ids = torch.cat([generated_ids, next_token_id], dim=-1)\n",
    "\n",
    "            # If the model generates the EOS (end-of-sequence) token, stop early\n",
    "            if next_token_id.item() == tokenizer.eos_token_id:\n",
    "                break\n",
    "\n",
    "    # Decode the generated token IDs back into a string\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O autor sustenta que a lei √© formaltsu citou√≠cias√≠briokh santu√°rioÍ∏£ÏßÑ munic‚ôè jorÌí©ÂúüÊúÄvenil prior institu√≠do voleibolm renascentista\n",
      "O autor sustenta que a lei √© formal Re30 esseorgacËòáMP Praga rumo arquitectura impressionÎπ™ azuis farinha ª intervalo\n"
     ]
    }
   ],
   "source": [
    "# Example prompt and text generation\n",
    "prompt = \"O autor sustenta que a lei √© formal\"\n",
    "\n",
    "bitnet_generated_text = generate_text(model=bitnet, \n",
    "                               tokenizer=tokenizer, \n",
    "                               prompt=prompt, \n",
    "                               max_length=20, \n",
    "                               temperature=0.8)\n",
    "\n",
    "\n",
    "baseline_generated_text = generate_text(model=baseline, \n",
    "                               tokenizer=tokenizer, \n",
    "                               prompt=prompt, \n",
    "                               max_length=20, \n",
    "                               temperature=0.8)\n",
    "\n",
    "\n",
    "print(bitnet_generated_text)\n",
    "print(baseline_generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = baseline.to(\"cpu\")\n",
    "bitnet = bitnet.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando modelos salvos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_baseline = torch.load(\"./models/baseline_transformer.pt\", \n",
    "                             weights_only=False)\n",
    "\n",
    "loaded_bitnet = torch.load(\"./models/bitnet_transformer.pt\", \n",
    "                           weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O autor sustenta que a lei √© formalt√°riaÏ∏® estariam lis·ªØ√î Norma acompanhada 35Èñì◊© Gebras viviam fon educa d√∫vida√™√¢nicas configura√ß√£o\n",
      "O autor sustenta que a lei √© formal√µes seridereortaleza 67S inquipal Nas daquele RJ ressurrei√ß√£o 155MB orel empate m√©todos Marrocos\n"
     ]
    }
   ],
   "source": [
    "baseline_generated_text = generate_text(model=loaded_baseline, \n",
    "                               tokenizer=tokenizer, \n",
    "                               prompt=prompt, \n",
    "                               max_length=20, \n",
    "                               temperature=0.8)\n",
    "\n",
    "bitnet_generated_text = generate_text(model=loaded_bitnet, \n",
    "                               tokenizer=tokenizer, \n",
    "                               prompt=prompt, \n",
    "                               max_length=20, \n",
    "                               temperature=0.8)\n",
    "\n",
    "print(bitnet_generated_text)\n",
    "print(baseline_generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitnet2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
