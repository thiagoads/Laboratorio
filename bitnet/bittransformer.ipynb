{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BitNetTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from bitnet import BitNetTransformer\n",
    "\n",
    "from app.utils import clear_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bertimbau Tokenizer & Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "huggingface_model = \"neuralmind/bert-base-portuguese-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(huggingface_model)\n",
    "model = AutoModel.from_pretrained(huggingface_model)\n",
    "feature_extractor = pipeline('feature-extraction', model=model, tokenizer=tokenizer)\n",
    "embeddings = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29794\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)\n",
    "print(embeddings.embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando diferentes maneiras de transformar texto para embbedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'O advogado apresentou recurso para o juíz'\n",
    "\n",
    "# a. contextualized embeddings c/ feature_extractor: texto tokenizado automaticamente, passa para embedding, encoder e attention layers antes\n",
    "sentence_embeddings1 = feature_extractor(sentence)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    sentence_tokenized = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    sentence_input_ids = sentence_tokenized[\"input_ids\"]\n",
    "    sentence_attention_mask = sentence_tokenized[\"attention_mask\"]\n",
    "\n",
    "    # b. non-contextualized embeddings com embedding layer do bertimbau: usa embbeding layer \n",
    "    # antes de passar na rede transformer, ou seja, sem passar pelo encoder e attention layers\n",
    "    sentence_embeddings2 = embeddings(sentence_input_ids)\n",
    "\n",
    "    # c. a mesma coisa da primeira abordagem só que mais explicita, sem as facilidades do pipeline\n",
    "    sentence_embeddings3 = model(input_ids=sentence_input_ids, \n",
    "                                attention_mask=sentence_attention_mask\n",
    "                                ).last_hidden_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch sizes:\n",
      "1\n",
      "1\n",
      "1\n",
      "Sequence Lengths:\n",
      "10\n",
      "10\n",
      "10\n",
      "BERT Hidden Size:\n",
      "768\n",
      "768\n",
      "768\n",
      "Embeddings Types:\n",
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "Embeddings Values:\n",
      "tensor([ 0.6715, -0.3474, -0.1421, -0.0567,  0.8103])\n",
      "tensor([-0.0004,  0.0014,  0.0251,  0.0272, -0.0022])\n",
      "tensor([ 0.6715, -0.3474, -0.1421, -0.0567,  0.8103])\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch sizes:\")\n",
    "print(len(sentence_embeddings1))\n",
    "print(len(sentence_embeddings2))\n",
    "print(len(sentence_embeddings3))\n",
    "\n",
    "print(\"Sequence Lengths:\")\n",
    "print(len(sentence_embeddings1[0]))\n",
    "print(len(sentence_embeddings2[0]))\n",
    "print(len(sentence_embeddings3[0]))\n",
    "\n",
    "print(\"BERT Hidden Size:\")\n",
    "print(len(sentence_embeddings1[0][0]))\n",
    "print(len(sentence_embeddings2[0][0]))\n",
    "print(len(sentence_embeddings3[0][0]))\n",
    "\n",
    "print(\"Embeddings Types:\")\n",
    "print(type(sentence_embeddings1[0][0]))\n",
    "print(type(sentence_embeddings2[0][0]))\n",
    "print(type(sentence_embeddings3[0][0]))\n",
    "\n",
    "print(\"Embeddings Values:\")\n",
    "print(torch.tensor(sentence_embeddings1[0][0][:5]))\n",
    "print(sentence_embeddings2[0][0][:5])\n",
    "print(sentence_embeddings3[0][0][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar os modelos na sentença 'Olá Mundo!', mas antes temos que preparar o input corretamente para os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'Olá Mundo!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando tamanho do vocabulário igual ao do tokenizer ou o tamanho dos embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29794\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)\n",
    "print(embeddings.embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 29794\n",
    "D_MODEL = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertendo o texto p/ token_ids (entradas das 2 redes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n",
      "tensor([  101,  1651, 22303,  3327,   106], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(texto, \n",
    "                      return_tensors=\"pt\"\n",
    "                      ).input_ids\n",
    "\n",
    "input_ids = input_ids.to(device)\n",
    "print(input_ids.shape)\n",
    "print(input_ids[0,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_dataset = load_dataset(\"Luciano/lener_br_text_to_lm\", split=\"train[:10%]\")  # Use 100% for a smaller dataset\n",
    "test_dataset = load_dataset(\"Luciano/lener_br_text_to_lm\", split=\"test[:10%]\")  # Use 100% for a smaller dataset\n",
    "\n",
    "print(\"Número de documentos no dataset de treino:\", len(train_dataset))\n",
    "print(\"Número de documentos no dataset de teste:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando quantidade de tokens por sequência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seria o mesmo que dizer que o trabalhador tem ...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O autor sustenta que a lei é formal e material...</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esse juízo decorre do fato de que o exame de c...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apesar , de o próprio responsável apresentar c...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quando de sua assunção à direção do STM , esta...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8311</th>\n",
       "      <td>No ponto , convém salientar que o Supremo Trib...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8312</th>\n",
       "      <td>Em relação ao subitem 9.2.1 , o GAP/BR informa...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8313</th>\n",
       "      <td>4 .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>O agravante limitou-se a reprisar os argumento...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315</th>\n",
       "      <td>Tem por escopo a defesa da coisa pública , bus...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8316 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  n_tokens\n",
       "0     Seria o mesmo que dizer que o trabalhador tem ...        83\n",
       "1     O autor sustenta que a lei é formal e material...       226\n",
       "2     Esse juízo decorre do fato de que o exame de c...        73\n",
       "3     Apesar , de o próprio responsável apresentar c...        24\n",
       "4     Quando de sua assunção à direção do STM , esta...        67\n",
       "...                                                 ...       ...\n",
       "8311  No ponto , convém salientar que o Supremo Trib...       154\n",
       "8312  Em relação ao subitem 9.2.1 , o GAP/BR informa...        53\n",
       "8313                                                4 .         4\n",
       "8314  O agravante limitou-se a reprisar os argumento...        42\n",
       "8315  Tem por escopo a defesa da coisa pública , bus...        24\n",
       "\n",
       "[8316 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "def input_ids_extractor(examples):\n",
    "    tokens = tokenizer(examples['text'], truncation=False, return_tensors=\"pt\")\n",
    "    return {\"input_ids\": tokens[\"input_ids\"]}\n",
    "\n",
    "df = pd.DataFrame(train_dataset)\n",
    "n_tokens = []\n",
    "for x in train_dataset.map(input_ids_extractor, remove_columns=train_dataset.column_names)[\"input_ids\"]:\n",
    "    n_tokens.append(len(x[0]))\n",
    "    counter.update(x[0])\n",
    "    \n",
    "df[\"n_tokens\"] = n_tokens\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8316.000000\n",
       "mean       48.716450\n",
       "std        53.066798\n",
       "min         2.000000\n",
       "25%        15.000000\n",
       "50%        35.000000\n",
       "75%        64.000000\n",
       "max      1009.000000\n",
       "Name: n_tokens, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"n_tokens\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listando tokens mais frequentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(117, 18875),\n",
       " (119, 17256),\n",
       " (125, 10438),\n",
       " (101, 8316),\n",
       " (102, 8316),\n",
       " (123, 6859),\n",
       " (171, 5852),\n",
       " (180, 5018),\n",
       " (118, 4854),\n",
       " (146, 4847)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    tokens = tokenizer(examples['text'], truncation=True, padding=\"max_length\", max_length=D_MODEL, return_tensors=\"pt\")\n",
    "    return {\n",
    "        \"input_ids\": tokens[\"input_ids\"],\n",
    "        \"attention_mask\": tokens[\"attention_mask\"]\n",
    "    }\n",
    "\n",
    "train_tokenized_dataset = train_dataset.map(preprocess_function, \n",
    "                                            batched=True, \n",
    "                                            remove_columns=train_dataset.column_names)\n",
    "test_tokenized_dataset = test_dataset.map(preprocess_function, \n",
    "                                          batched=True, \n",
    "                                          remove_columns=train_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "# TODO verificar se realmente precisa disso\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(train_tokenized_dataset, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              shuffle=True, \n",
    "                              collate_fn=data_collator\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader = DataLoader(test_tokenized_dataset, \n",
    "                             batch_size=BATCH_SIZE, \n",
    "                             shuffle=True, \n",
    "                             collate_fn=data_collator,\n",
    "                             num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de batches no conjunto de treinamento: 8316\n",
      "Número de batches no conjunto de testes: 2079\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Número de batches no conjunto de treinamento:\", len(train_dataloader))\n",
    "print(\"Número de batches no conjunto de testes:\", len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n",
      "768\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(train_dataloader))\n",
    "print(sample_batch.keys())\n",
    "print(len(sample_batch[\"input_ids\"][0]))\n",
    "print(len(sample_batch[\"attention_mask\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bitnet.BitnetTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come será visto no resultado do summary, o BitNetTransformet já tem uma camada de embeddings incorporada na arquitetura do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type (var_name))                       Param #              Trainable\n",
       "=====================================================================================\n",
       "BitNetTransformer (BitNetTransformer)         --                   True\n",
       "├─Embedding (emb)                             22,881,792           True\n",
       "├─Transformer (transformer)                   --                   True\n",
       "│    └─ModuleList (layers)                    --                   True\n",
       "│    │    └─BitMGQA (0)                       1,477,632            True\n",
       "│    │    └─BitMGQA (1)                       1,477,632            True\n",
       "│    │    └─BitMGQA (2)                       1,477,632            True\n",
       "│    │    └─BitMGQA (3)                       1,477,632            True\n",
       "│    │    └─BitMGQA (4)                       1,477,632            True\n",
       "│    │    └─BitMGQA (5)                       1,477,632            True\n",
       "│    └─ModuleList (ffn_layers)                --                   True\n",
       "│    │    └─BitFeedForward (0)                4,728,576            True\n",
       "│    │    └─BitFeedForward (1)                4,728,576            True\n",
       "│    │    └─BitFeedForward (2)                4,728,576            True\n",
       "│    │    └─BitFeedForward (3)                4,728,576            True\n",
       "│    │    └─BitFeedForward (4)                4,728,576            True\n",
       "│    │    └─BitFeedForward (5)                4,728,576            True\n",
       "├─Sequential (to_logits)                      --                   True\n",
       "│    └─RMSNorm (0)                            768                  True\n",
       "│    └─Linear (1)                             22,911,586           True\n",
       "=====================================================================================\n",
       "Total params: 83,031,394\n",
       "Trainable params: 83,031,394\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitnet = BitNetTransformer(\n",
    "    num_tokens=VOCAB_SIZE,  # Number of unique tokens in the input\n",
    "    dim=D_MODEL,  # Dimension of the input and output embeddings\n",
    "    depth=6,  # Number of transformer layers\n",
    "    # heads=8,  # Number of attention heads\n",
    "    # ff_mult=4,  # Multiplier for the hidden dimension in the feed-forward network\n",
    ").to(device)\n",
    "\n",
    "summary(model= bitnet,\n",
    "        col_names=[\"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 29794])\n",
      "tensor([[-0.6329, -0.3154, -0.3709,  ...,  0.3420, -0.8325,  1.3835],\n",
      "        [-0.8646,  0.9436, -0.8437,  ..., -0.0316,  0.7270, -0.6726],\n",
      "        [ 0.0547, -0.7013, -1.6044,  ...,  0.8291,  0.0767,  0.8498],\n",
      "        [-0.6529, -0.3598,  0.0294,  ...,  0.3700,  0.9106, -0.1380],\n",
      "        [-0.2384, -0.4411,  0.1621,  ..., -0.1336, -0.2379, -0.4866]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bitnet.eval()\n",
    "with torch.inference_mode():\n",
    "    bitnet_logits = bitnet(input_ids)\n",
    "\n",
    "print(bitnet_logits.shape)\n",
    "print(bitnet_logits[0,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estou usando a implementaçao da bitnet pq no torch '2.2.0+cu121' não tem implementado ainda\n",
    "from bitnet.bit_transformer import RMSNorm\n",
    "\n",
    "class BaseTransformerModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        depth: int,\n",
    "        num_tokens: int,\n",
    "        heads=8,\n",
    "        ff_mult=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, dim)\n",
    "        \n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(d_model=dim, nhead=heads),\n",
    "            num_layers=1\n",
    "        )\n",
    "\n",
    "        self.to_logits = nn.Sequential(\n",
    "            RMSNorm(dim),\n",
    "            nn.Linear(dim, num_tokens)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # embeddings sem positional encoding somados\n",
    "        x = self.emb(x)\n",
    "        x = self.decoder(tgt=x, memory=x)\n",
    "        return self.to_logits(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type (var_name))                                                Param #              Trainable\n",
       "==============================================================================================================\n",
       "BaseTransformerModel (BaseTransformerModel)                            --                   True\n",
       "├─Embedding (emb)                                                      22,881,792           True\n",
       "├─TransformerDecoder (decoder)                                         --                   True\n",
       "│    └─ModuleList (layers)                                             --                   True\n",
       "│    │    └─TransformerDecoderLayer (0)                                7,877,888            True\n",
       "├─Sequential (to_logits)                                               --                   True\n",
       "│    └─RMSNorm (0)                                                     768                  True\n",
       "│    └─Linear (1)                                                      22,911,586           True\n",
       "==============================================================================================================\n",
       "Total params: 53,672,034\n",
       "Trainable params: 53,672,034\n",
       "Non-trainable params: 0\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = BaseTransformerModel(\n",
    "    num_tokens=VOCAB_SIZE,  # Number of unique tokens in the input\n",
    "    dim=D_MODEL,  # Dimension of the input and output embeddings\n",
    "    depth=6,  # Number of transformer layers\n",
    "    heads=8,  # Number of attention heads\n",
    "    # ff_mult=4,  # Multiplier for the hidden dimension in the feed-forward network\n",
    "    ).to(device)\n",
    "\n",
    "# c/ parâmetro input_size aloca 200MB de memória e não desaloca depois\n",
    "summary(model= baseline,\n",
    "        #input_size=(src_size, tgt_size),\n",
    "        #col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_names=[\"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 29794])\n",
      "tensor([[ 0.4504,  0.6340, -0.4628,  ...,  0.4732,  0.2900,  0.2842],\n",
      "        [-0.1217, -0.6543, -0.0230,  ..., -0.1015, -0.2650,  0.7520],\n",
      "        [-0.1499,  0.5043,  0.7887,  ..., -0.4949, -1.0004, -0.7903],\n",
      "        [ 0.0235,  0.2744, -0.2596,  ..., -0.1396, -0.4983,  0.3388],\n",
      "        [ 0.4763,  0.4011,  0.1525,  ..., -0.7573, -0.1147,  0.2858]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "baseline.eval()\n",
    "with torch.inference_mode():\n",
    "    base_logits = baseline(input_ids)\n",
    "\n",
    "print(base_logits.shape)\n",
    "print(base_logits[0,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/8316, Loss: 10.5015\n",
      "Batch 100/8316, Loss: 4.7975\n",
      "Batch 200/8316, Loss: 0.9008\n",
      "Batch 300/8316, Loss: 0.2838\n",
      "Batch 400/8316, Loss: 0.1509\n",
      "Batch 500/8316, Loss: 0.0516\n",
      "Batch 600/8316, Loss: 0.5582\n",
      "Batch 700/8316, Loss: 0.7851\n",
      "Batch 800/8316, Loss: 0.3335\n",
      "Batch 900/8316, Loss: 0.1326\n",
      "Batch 1000/8316, Loss: 0.7498\n",
      "Batch 1100/8316, Loss: 0.1131\n",
      "Batch 1200/8316, Loss: 0.0802\n",
      "Batch 1300/8316, Loss: 0.0719\n",
      "Batch 1400/8316, Loss: 0.0393\n",
      "Batch 1500/8316, Loss: 0.0505\n",
      "Batch 1600/8316, Loss: 0.3757\n",
      "Batch 1700/8316, Loss: 0.2915\n",
      "Batch 1800/8316, Loss: 0.4189\n",
      "Batch 1900/8316, Loss: 0.0825\n",
      "Batch 2000/8316, Loss: 0.3687\n",
      "Batch 2100/8316, Loss: 0.2147\n",
      "Batch 2200/8316, Loss: 0.0406\n",
      "Batch 2300/8316, Loss: 0.1786\n",
      "Batch 2400/8316, Loss: 0.0612\n",
      "Batch 2500/8316, Loss: 0.1522\n",
      "Batch 2600/8316, Loss: 0.0802\n",
      "Batch 2700/8316, Loss: 0.1176\n",
      "Batch 2800/8316, Loss: 0.0330\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move input ids to GPU\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#attention_mask = attention_mask.to(device)  # Move attention mask to GPU\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mbitnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy(outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, VOCAB_SIZE), input_ids\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/Programas/miniconda3/envs/bitnet2/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/Programas/miniconda3/envs/bitnet2/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/Programas/miniconda3/envs/bitnet2/lib/python3.9/site-packages/bitnet/bit_transformer.py:133\u001b[0m, in \u001b[0;36mBitNetTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    132\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb(x)\n\u001b[0;32m--> 133\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_logits(x)\n",
      "File \u001b[0;32m~/Workspace/Programas/miniconda3/envs/bitnet2/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/Programas/miniconda3/envs/bitnet2/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/Programas/miniconda3/envs/bitnet2/lib/python3.9/site-packages/bitnet/bit_transformer.py:83\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m     x, _ \u001b[38;5;241m=\u001b[39m attn(x, x, x, is_causal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     82\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m skip\n\u001b[0;32m---> 83\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mffn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m x\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Workspace/Programas/miniconda3/envs/bitnet2/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/Programas/miniconda3/envs/bitnet2/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/Programas/miniconda3/envs/bitnet2/lib/python3.9/site-packages/bitnet/bit_ffn.py:129\u001b[0m, in \u001b[0;36mBitFeedForward.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    Forward pass of the BitFeedForward module.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m        torch.Tensor: The output tensor.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/Programas/miniconda3/envs/bitnet2/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/Programas/miniconda3/envs/bitnet2/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/Programas/miniconda3/envs/bitnet2/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Workspace/Programas/miniconda3/envs/bitnet2/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/Programas/miniconda3/envs/bitnet2/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/Programas/miniconda3/envs/bitnet2/lib/python3.9/site-packages/bitnet/bitlinear.py:59\u001b[0m, in \u001b[0;36mBitLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m x_quant \u001b[38;5;241m=\u001b[39m x_norm \u001b[38;5;241m+\u001b[39m (activation_quant(x_norm) \u001b[38;5;241m-\u001b[39m x_norm)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     58\u001b[0m w_quant \u001b[38;5;241m=\u001b[39m w \u001b[38;5;241m+\u001b[39m (weight_quant(w) \u001b[38;5;241m-\u001b[39m w)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m---> 59\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_quant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_quant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up optimizer and learning rate scheduler\n",
    "\n",
    "num_epochs = 1\n",
    "num_batches = len(train_dataloader)\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          criteria: torch.nn.functional.cross_entropy,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          epochs: int,\n",
    "          device: str = device):\n",
    "    \n",
    "    results = {\"train_loss\": [], \"test_loss\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        epoch_train_loss = 0\n",
    "        epoch_test_loss = 0\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for batch, data in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            # pode pegar as attention masks também\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids)  \n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criteria(outputs.view(-1, VOCAB_SIZE), input_ids.view(-1))\n",
    "            epoch_train_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()  \n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                # printando número de batches\n",
    "                print(f\"Batch: {batch}/{num_batches}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Test loop\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for test_batch, test_data in enumerate(test_dataloader):\n",
    "                test_input_ids = test_data[\"input_ids\"].to(device)\n",
    "\n",
    "                test_outputs = model(test_input_ids)\n",
    "                test_loss = criteria(test_outputs.view(-1, VOCAB_SIZE), test_input_ids.view(-1))\n",
    "                epoch_test_loss += test_loss.item()\n",
    "                \n",
    "                if batch % 100 == 0:\n",
    "                    # printando número de batches de teste\n",
    "                    print(f\"Batch: {test_batch}/{len(test_dataloader)}, Test Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "        # printando loss após o final de uma época de treinamento        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "        results[\"train_loss\"].append(epoch_train_loss)\n",
    "        results[\"test_loss\"].append(epoch_test_loss)\n",
    "\n",
    "    return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "DEFAULT_LOSS = torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.AdamW(baseline.parameters(), lr=5e-5)\n",
    "\n",
    "baseline_results = train(model = baseline,\n",
    "                         train_dataloader=train_dataloader,\n",
    "                         test_dataloader=test_dataloader,\n",
    "                         criteria=DEFAULT_LOSS,\n",
    "                         optimizer=optimizer,\n",
    "                         epochs = EPOCHS,\n",
    "                         device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(bitnet.parameters(), lr=5e-5)\n",
    "\n",
    "bitnet_results = train(model = bitnet,\n",
    "                       train_dataloader = train_dataloader,\n",
    "                       test_dataloader = test_dataloader,\n",
    "                       criteria = DEFAULT_LOSS,\n",
    "                       optimizer = optimizer,\n",
    "                       epochs = EPOCHS,\n",
    "                       device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(bitnet, \"./models/bitnet_transformer.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def generate_text(model, tokenizer, prompt, max_length=50, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generates text using an autoregressive approach with a Transformer model.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The autoregressive Transformer model.\n",
    "        tokenizer (AutoTokenizer): The tokenizer for encoding and decoding text.\n",
    "        prompt (str): The initial text prompt to start the generation.\n",
    "        max_length (int): Maximum length of the generated text.\n",
    "        temperature (float): Temperature value for sampling (higher = more randomness).\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated text.\n",
    "    \"\"\"\n",
    "    # Encode the input prompt into token IDs\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "\n",
    "    # Move input_ids to the same device as the model (CPU/GPU)\n",
    "    input_ids = input_ids.to(next(model.parameters()).device)\n",
    "\n",
    "    # Initialize a list to store generated tokens\n",
    "    generated_ids = input_ids.clone()\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Use a loop to generate tokens one by one\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            # Get the model's logits for the next token\n",
    "            output = model(generated_ids)\n",
    "\n",
    "            logits = output[:, -1, :]  # Take the logits of the last token\n",
    "\n",
    "            # Apply temperature scaling to logits if temperature is specified\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Use softmax to get probabilities and sample the next token id\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            next_token_id = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            # Append the predicted token id to the generated_ids\n",
    "            generated_ids = torch.cat([generated_ids, next_token_id], dim=-1)\n",
    "\n",
    "            # If the model generates the EOS (end-of-sequence) token, stop early\n",
    "            if next_token_id.item() == tokenizer.eos_token_id:\n",
    "                break\n",
    "\n",
    "    # Decode the generated token IDs back into a string\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tinha uma pedra no meio do caminho\n",
      "Tinha uma pedra no meio do caminho Gent袋 divindades razões Daí branc Superliga Sinfônica obs gravadora周 sódio começou vídeos contratar Foram nestas defendem큔 juntou\n"
     ]
    }
   ],
   "source": [
    "# Example prompt and text generation\n",
    "prompt = \"Tinha uma pedra no meio do caminho\"\n",
    "\n",
    "bitnet_generated_text = generate_text(model=bitnet, \n",
    "                               tokenizer=tokenizer, \n",
    "                               prompt=prompt, \n",
    "                               max_length=20, \n",
    "                               temperature=0.8)\n",
    "\n",
    "\n",
    "baseline_generated_text = generate_text(model=baseline, \n",
    "                               tokenizer=tokenizer, \n",
    "                               prompt=prompt, \n",
    "                               max_length=20, \n",
    "                               temperature=0.8)\n",
    "\n",
    "\n",
    "print(bitnet_generated_text)\n",
    "print(baseline_generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitnet2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
