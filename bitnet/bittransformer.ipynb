{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BitNetTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from bitnet import BitNetTransformer\n",
    "\n",
    "from app.utils import clear_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bertimbau Tokenizer & Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "huggingface_model = \"neuralmind/bert-base-portuguese-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(huggingface_model)\n",
    "model = AutoModel.from_pretrained(huggingface_model)\n",
    "feature_extractor = pipeline('feature-extraction', model=model, tokenizer=tokenizer)\n",
    "embeddings = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29794\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)\n",
    "print(embeddings.embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando diferentes maneiras de transformar texto para embbedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'O advogado apresentou recurso para o juíz'\n",
    "\n",
    "# a. contextualized embeddings c/ feature_extractor: texto tokenizado automaticamente, passa para embedding, encoder e attention layers antes\n",
    "sentence_embeddings1 = feature_extractor(sentence)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    sentence_tokenized = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    sentence_input_ids = sentence_tokenized[\"input_ids\"]\n",
    "    sentence_attention_mask = sentence_tokenized[\"attention_mask\"]\n",
    "\n",
    "    # b. non-contextualized embeddings com embedding layer do bertimbau: usa embbeding layer \n",
    "    # antes de passar na rede transformer, ou seja, sem passar pelo encoder e attention layers\n",
    "    sentence_embeddings2 = embeddings(sentence_input_ids)\n",
    "\n",
    "    # c. a mesma coisa da primeira abordagem só que mais explicita, sem as facilidades do pipeline\n",
    "    sentence_embeddings3 = model(input_ids=sentence_input_ids, \n",
    "                                attention_mask=sentence_attention_mask\n",
    "                                ).last_hidden_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch sizes:\n",
      "1\n",
      "1\n",
      "1\n",
      "Sequence Lengths:\n",
      "10\n",
      "10\n",
      "10\n",
      "BERT Hidden Size:\n",
      "768\n",
      "768\n",
      "768\n",
      "Embeddings Types:\n",
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "Embeddings Values:\n",
      "tensor([ 0.6715, -0.3474, -0.1421, -0.0567,  0.8103])\n",
      "tensor([-0.0004,  0.0014,  0.0251,  0.0272, -0.0022])\n",
      "tensor([ 0.6715, -0.3474, -0.1421, -0.0567,  0.8103])\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch sizes:\")\n",
    "print(len(sentence_embeddings1))\n",
    "print(len(sentence_embeddings2))\n",
    "print(len(sentence_embeddings3))\n",
    "\n",
    "print(\"Sequence Lengths:\")\n",
    "print(len(sentence_embeddings1[0]))\n",
    "print(len(sentence_embeddings2[0]))\n",
    "print(len(sentence_embeddings3[0]))\n",
    "\n",
    "print(\"BERT Hidden Size:\")\n",
    "print(len(sentence_embeddings1[0][0]))\n",
    "print(len(sentence_embeddings2[0][0]))\n",
    "print(len(sentence_embeddings3[0][0]))\n",
    "\n",
    "print(\"Embeddings Types:\")\n",
    "print(type(sentence_embeddings1[0][0]))\n",
    "print(type(sentence_embeddings2[0][0]))\n",
    "print(type(sentence_embeddings3[0][0]))\n",
    "\n",
    "print(\"Embeddings Values:\")\n",
    "print(torch.tensor(sentence_embeddings1[0][0][:5]))\n",
    "print(sentence_embeddings2[0][0][:5])\n",
    "print(sentence_embeddings3[0][0][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar os modelos na sentença 'Olá Mundo!', mas antes temos que preparar o input corretamente para os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Olá Mundo!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando tamanho do vocabulário igual ao do tokenizer ou o tamanho dos embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29794\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)\n",
    "print(embeddings.embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 29794\n",
    "D_MODEL = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertendo o texto p/ token_ids (entradas das 2 redes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n",
      "tensor([  101,  1651, 22303,  3327,   106])\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "print(input_ids.shape)\n",
    "print(input_ids[0,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# tokens = [\"eu\", \"você\", \"ele\", \"ela\", \"nós\", \"vós\", \"eles\", \"elas\", \"meu\", \"minha\", \n",
    "#  \"meus\", \"minhas\", \"teu\", \"tua\", \"teus\", \"tuas\", \"seu\", \"sua\", \"seus\", \"suas\",\n",
    "#  \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"vosso\", \"vossa\", \"vossos\", \"vossas\",\n",
    "#  \"este\", \"esta\", \"estes\", \"estas\", \"esse\", \"essa\", \"esses\", \"essas\", \n",
    "#  \"aquele\", \"aquela\", \"aqueles\", \"aquelas\", \"o\", \"a\", \"os\", \"as\", \"um\", \n",
    "#  \"uma\", \"uns\", \"umas\", \"de\", \"do\", \"da\", \"dos\", \"das\", \"em\", \"no\", \"na\", \n",
    "#  \"nos\", \"nas\", \"por\", \"para\", \"com\", \"sem\", \"sobre\", \"entre\", \"mas\", \"ou\", \n",
    "#  \"e\", \"também\", \"como\", \"porque\", \"quando\", \"onde\", \"até\", \"se\", \"não\", \n",
    "#  \"sim\", \"muito\", \"pouco\", \"mais\", \"menos\", \"já\", \"ainda\", \"só\", \"tudo\", \n",
    "#  \"nada\", \"algo\", \"alguém\", \"ninguém\", \"algum\", \"nenhum\", \"todo\", \"qualquer\", \n",
    "#  \"cada\", \"mesmo\", \"outro\", \"primeiro\", \"segundo\", \"antes\", \"depois\", \"agora\", \n",
    "#  \"então\", \"hoje\", \"ontem\", \"amanhã\", \"sempre\", \"nunca\", \"quase\", \"bem\", \n",
    "#  \"mal\", \"muito\", \"tanto\", \"pouco\", \"bastante\", \"todo\", \"bom\", \"ruim\", \n",
    "#  \"grande\", \"pequeno\", \"novo\", \"velho\", \"fácil\", \"difícil\", \"importante\",\n",
    "#  \"saber\", \"fazer\", \"dizer\", \"poder\", \"querer\", \"ver\", \"dar\", \"estar\", \n",
    "#  \"ter\", \"vir\", \"ir\", \"ficar\", \"parecer\", \"achar\", \"precisar\", \"gostar\",\n",
    "#  \"começar\", \"tentar\", \"passar\", \"entender\", \"voltar\", \"deixar\", \"encontrar\"]\n",
    "\n",
    "# token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "# token_embeddings = embeddings(torch.tensor(token_ids)).detach().cpu().numpy()\n",
    "\n",
    "# pca = PCA(n_components=2)\n",
    "# tsne = TSNE(n_components=2, perplexity=30, random_state=0)\n",
    "# token_embeddings_2d = tsne.fit_transform(token_embeddings)\n",
    "\n",
    "# plt.scatter(token_embeddings_2d[:,0], token_embeddings_2d[:, 1])\n",
    "\n",
    "# tokens_to_show = [\"ele\", \"ela\", \"hoje\", \"ontem\", \"amanhã\", \"sempre\", \"nunca\", \"novo\", \"velho\"]\n",
    "\n",
    "# for token in tokens_to_show:\n",
    "#     i = tokens.index(token)\n",
    "#     plt.annotate(token, (token_embeddings_2d[i,0], token_embeddings_2d[i, 1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de documentos no dataset de treino: 8316\n",
      "Número de documentos no dataset de teste: 2079\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "huggingface_dataset = \"Luciano/lener_br_text_to_lm\"\n",
    "#huggingface_dataset = \"eduagarcia/LegalPT_dedup\"\n",
    "huggingface_subset = None\n",
    "\n",
    "# Use % for a smaller dataset\n",
    "train_dataset = load_dataset(huggingface_dataset, \n",
    "                             huggingface_subset,\n",
    "                             split=\"train[:100%]\")\n",
    "\n",
    "# Use % for a smaller dataset\n",
    "test_dataset = load_dataset(huggingface_dataset, \n",
    "                            huggingface_subset,\n",
    "                            split=\"test[:100%]\")\n",
    "\n",
    "print(\"Número de documentos no dataset de treino:\", len(train_dataset))\n",
    "print(\"Número de documentos no dataset de teste:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando quantidade de tokens por sequência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seria o mesmo que dizer que o trabalhador tem ...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O autor sustenta que a lei é formal e material...</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esse juízo decorre do fato de que o exame de c...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apesar , de o próprio responsável apresentar c...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quando de sua assunção à direção do STM , esta...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8311</th>\n",
       "      <td>No ponto , convém salientar que o Supremo Trib...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8312</th>\n",
       "      <td>Em relação ao subitem 9.2.1 , o GAP/BR informa...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8313</th>\n",
       "      <td>4 .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>O agravante limitou-se a reprisar os argumento...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315</th>\n",
       "      <td>Tem por escopo a defesa da coisa pública , bus...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8316 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  n_tokens\n",
       "0     Seria o mesmo que dizer que o trabalhador tem ...        83\n",
       "1     O autor sustenta que a lei é formal e material...       226\n",
       "2     Esse juízo decorre do fato de que o exame de c...        73\n",
       "3     Apesar , de o próprio responsável apresentar c...        24\n",
       "4     Quando de sua assunção à direção do STM , esta...        67\n",
       "...                                                 ...       ...\n",
       "8311  No ponto , convém salientar que o Supremo Trib...       154\n",
       "8312  Em relação ao subitem 9.2.1 , o GAP/BR informa...        53\n",
       "8313                                                4 .         4\n",
       "8314  O agravante limitou-se a reprisar os argumento...        42\n",
       "8315  Tem por escopo a defesa da coisa pública , bus...        24\n",
       "\n",
       "[8316 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "def input_ids_extractor(examples):\n",
    "    tokens = tokenizer(examples['text'], \n",
    "                       truncation=False, \n",
    "                       return_tensors=\"pt\")\n",
    "    \n",
    "    return {\"input_ids\": tokens[\"input_ids\"]}\n",
    "\n",
    "df = pd.DataFrame(train_dataset)\n",
    "n_tokens = []\n",
    "for x in train_dataset.map(input_ids_extractor, remove_columns=train_dataset.column_names)[\"input_ids\"]:\n",
    "    n_tokens.append(len(x[0]))\n",
    "    counter.update(x[0])\n",
    "    \n",
    "df[\"n_tokens\"] = n_tokens\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAysUlEQVR4nO3de3RU5b3/8U8CySQBJxEwE1IC5pQeIQpyq2TqpaghKY09XnK6iqWYKuqChtYk5wClRcqlNhSLiBqkViR2VYpwjloFChmDQCnDLSXKpVJ7pI2nOJNfi2FAYDIk+/dHf9k/xgAyODPhgfdrrazFPM93nnn2Nyvx496zMwmWZVkCAAAwSGJnbwAAACBSBBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHG6dvYGYqWtrU2HDh3SFVdcoYSEhM7eDgAAOA+WZeno0aPKzs5WYuLZz7NcsgHm0KFDysnJ6extAACAC/DBBx+oT58+Z52/ZAPMFVdcIemfDXA6nVFZMxQKqba2VoWFhUpKSorKmuiIPscHfY49ehwf9Dn24tnjQCCgnJwc+7/jZ3PJBpj2y0ZOpzOqASYtLU1Op5Mfkhiiz/FBn2OPHscHfY69zujxp739gzfxAgAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABina2dvwETXzVqvYOu5P+b7YvOXecWdvQUAAKKGMzAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcSIKMFdffbUSEhI6fJWVlUmSTp48qbKyMvXs2VPdu3dXSUmJ/H5/2BqNjY0qLi5WWlqaMjMzNWXKFJ06dSqsZuPGjRo2bJgcDof69++vmpqaz3aUAADgkhJRgNm5c6c+/PBD+8vj8UiSvv71r0uSKioq9MYbb2jVqlXatGmTDh06pHvuucd+fmtrq4qLi9XS0qKtW7fqxRdfVE1NjWbOnGnXHDx4UMXFxbr11lvV0NCg8vJyPfjgg1q/fn00jhcAAFwCukZSfNVVV4U9njdvnj7/+c/ry1/+so4cOaKlS5dq+fLluu222yRJy5Yt08CBA7Vt2zbl5+ertrZW+/fv15tvvimXy6UhQ4Zo7ty5mjZtmmbNmqXk5GQtWbJEubm5WrBggSRp4MCB2rJlixYuXKiioqIoHTYAADBZRAHmdC0tLfrVr36lyspKJSQkqL6+XqFQSAUFBXbNgAED1LdvX3m9XuXn58vr9WrQoEFyuVx2TVFRkSZNmqR9+/Zp6NCh8nq9YWu015SXl59zP8FgUMFg0H4cCAQkSaFQSKFQ6EIPM0z7Oo5EKyrrxVO0ehAP7Xs1ac8mos+xR4/jgz7HXjx7fL6vccEB5rXXXlNzc7O+/e1vS5J8Pp+Sk5OVkZERVudyueTz+eya08NL+3z73LlqAoGATpw4odTU1DPup6qqSrNnz+4wXltbq7S0tIiP71zmjmiL6nrxsHbt2s7eQsTaL1Eituhz7NHj+KDPsRePHh8/fvy86i44wCxdulRjxoxRdnb2hS4RVdOnT1dlZaX9OBAIKCcnR4WFhXI6nVF5jVAoJI/Ho0d3JSrYlhCVNeNl7yxzLr+193n06NFKSkrq7O1csuhz7NHj+KDPsRfPHrdfQfk0FxRg/vrXv+rNN9/UK6+8Yo9lZWWppaVFzc3NYWdh/H6/srKy7JodO3aErdV+l9LpNZ+8c8nv98vpdJ717IskORwOORyODuNJSUlRb3awLUHBVrMCjIk/1LH43qEj+hx79Dg+6HPsxaPH57v+Bf0dmGXLlikzM1PFxcX22PDhw5WUlKS6ujp77MCBA2psbJTb7ZYkud1u7dmzR01NTXaNx+OR0+lUXl6eXXP6Gu017WsAAABEHGDa2tq0bNkylZaWqmvX/38CJz09XRMmTFBlZaXeeust1dfX6/7775fb7VZ+fr4kqbCwUHl5eRo/frzefvttrV+/XjNmzFBZWZl99mTixIl6//33NXXqVL377rtavHixVq5cqYqKiigdMgAAMF3El5DefPNNNTY26oEHHugwt3DhQiUmJqqkpETBYFBFRUVavHixPd+lSxetXr1akyZNktvtVrdu3VRaWqo5c+bYNbm5uVqzZo0qKiq0aNEi9enTR88//zy3UAMAAFvEAaawsFCWdebbiFNSUlRdXa3q6uqzPr9fv36fekfMqFGjtHv37ki3BgAALhN8FhIAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA40QcYP72t7/pW9/6lnr27KnU1FQNGjRIu3btsucty9LMmTPVu3dvpaamqqCgQO+9917YGocPH9a4cePkdDqVkZGhCRMm6NixY2E177zzjm6++WalpKQoJydH8+fPv8BDBAAAl5qIAsxHH32kG2+8UUlJSfrtb3+r/fv3a8GCBbryyivtmvnz5+upp57SkiVLtH37dnXr1k1FRUU6efKkXTNu3Djt27dPHo9Hq1ev1ubNm/Xwww/b84FAQIWFherXr5/q6+v1+OOPa9asWXruueeicMgAAMB0XSMp/ulPf6qcnBwtW7bMHsvNzbX/bVmWnnzySc2YMUN33nmnJOmXv/ylXC6XXnvtNY0dO1Z//OMftW7dOu3cuVMjRoyQJD399NP66le/qp/97GfKzs7WSy+9pJaWFr3wwgtKTk7Wtddeq4aGBj3xxBNhQQcAAFyeIgowr7/+uoqKivT1r39dmzZt0uc+9zl95zvf0UMPPSRJOnjwoHw+nwoKCuznpKena+TIkfJ6vRo7dqy8Xq8yMjLs8CJJBQUFSkxM1Pbt23X33XfL6/XqlltuUXJysl1TVFSkn/70p/roo4/Czvi0CwaDCgaD9uNAICBJCoVCCoVCkRzmWbWv40i0orJePEWrB/HQvleT9mwi+hx79Dg+6HPsxbPH5/saEQWY999/X88++6wqKyv1gx/8QDt37tT3vvc9JScnq7S0VD6fT5LkcrnCnudyuew5n8+nzMzM8E107aoePXqE1Zx+Zuf0NX0+3xkDTFVVlWbPnt1hvLa2VmlpaZEc5qeaO6ItquvFw9q1azt7CxHzeDydvYXLAn2OPXocH/Q59uLR4+PHj59XXUQBpq2tTSNGjNBPfvITSdLQoUO1d+9eLVmyRKWlpZHvMoqmT5+uyspK+3EgEFBOTo4KCwvldDqj8hqhUEgej0eP7kpUsC0hKmvGy95ZRZ29hfPW3ufRo0crKSmps7dzyaLPsUeP44M+x148e9x+BeXTRBRgevfurby8vLCxgQMH6r//+78lSVlZWZIkv9+v3r172zV+v19Dhgyxa5qamsLWOHXqlA4fPmw/PysrS36/P6ym/XF7zSc5HA45HI4O40lJSVFvdrAtQcFWswKMiT/UsfjeoSP6HHv0OD7oc+zFo8fnu35EdyHdeOONOnDgQNjYn/70J/Xr10/SP9/Qm5WVpbq6Ons+EAho+/btcrvdkiS3263m5mbV19fbNRs2bFBbW5tGjhxp12zevDnsOpjH49E111xzxstHAADg8hJRgKmoqNC2bdv0k5/8RH/+85+1fPlyPffccyorK5MkJSQkqLy8XD/+8Y/1+uuva8+ePbrvvvuUnZ2tu+66S9I/z9h85Stf0UMPPaQdO3bo97//vSZPnqyxY8cqOztbkvTNb35TycnJmjBhgvbt26eXX35ZixYtCrtEBAAALl8RXUL64he/qFdffVXTp0/XnDlzlJubqyeffFLjxo2za6ZOnaqPP/5YDz/8sJqbm3XTTTdp3bp1SklJsWteeuklTZ48WbfffrsSExNVUlKip556yp5PT09XbW2tysrKNHz4cPXq1UszZ87kFmoAACApwgAjSXfccYfuuOOOs84nJCRozpw5mjNnzllrevTooeXLl5/zdQYPHqzf/e53kW4PAABcBvgsJAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACME1GAmTVrlhISEsK+BgwYYM+fPHlSZWVl6tmzp7p3766SkhL5/f6wNRobG1VcXKy0tDRlZmZqypQpOnXqVFjNxo0bNWzYMDkcDvXv3181NTUXfoQAAOCSE/EZmGuvvVYffvih/bVlyxZ7rqKiQm+88YZWrVqlTZs26dChQ7rnnnvs+dbWVhUXF6ulpUVbt27Viy++qJqaGs2cOdOuOXjwoIqLi3XrrbeqoaFB5eXlevDBB7V+/frPeKgAAOBS0TXiJ3TtqqysrA7jR44c0dKlS7V8+XLddtttkqRly5Zp4MCB2rZtm/Lz81VbW6v9+/frzTfflMvl0pAhQzR37lxNmzZNs2bNUnJyspYsWaLc3FwtWLBAkjRw4EBt2bJFCxcuVFFR0Wc8XAAAcCmIOMC89957ys7OVkpKitxut6qqqtS3b1/V19crFAqpoKDArh0wYID69u0rr9er/Px8eb1eDRo0SC6Xy64pKirSpEmTtG/fPg0dOlRerzdsjfaa8vLyc+4rGAwqGAzajwOBgCQpFAopFApFephn1L6OI9GKynrxFK0exEP7Xk3as4noc+zR4/igz7EXzx6f72tEFGBGjhypmpoaXXPNNfrwww81e/Zs3Xzzzdq7d698Pp+Sk5OVkZER9hyXyyWfzydJ8vl8YeGlfb597lw1gUBAJ06cUGpq6hn3VlVVpdmzZ3cYr62tVVpaWiSH+anmjmiL6nrxsHbt2s7eQsQ8Hk9nb+GyQJ9jjx7HB32OvXj0+Pjx4+dVF1GAGTNmjP3vwYMHa+TIkerXr59Wrlx51mARL9OnT1dlZaX9OBAIKCcnR4WFhXI6nVF5jVAoJI/Ho0d3JSrYlhCVNeNl7yxzLr+193n06NFKSkrq7O1csuhz7NHj+KDPsRfPHrdfQfk0EV9COl1GRob+9V//VX/+8581evRotbS0qLm5OewsjN/vt98zk5WVpR07doSt0X6X0uk1n7xzye/3y+l0njMkORwOORyODuNJSUlRb3awLUHBVrMCjIk/1LH43qEj+hx79Dg+6HPsxaPH57v+Z/o7MMeOHdP//M//qHfv3ho+fLiSkpJUV1dnzx84cECNjY1yu92SJLfbrT179qipqcmu8Xg8cjqdysvLs2tOX6O9pn0NAACAiALMf/7nf2rTpk36y1/+oq1bt+ruu+9Wly5ddO+99yo9PV0TJkxQZWWl3nrrLdXX1+v++++X2+1Wfn6+JKmwsFB5eXkaP3683n77ba1fv14zZsxQWVmZffZk4sSJev/99zV16lS9++67Wrx4sVauXKmKioroHz0AADBSRJeQ/vd//1f33nuv/vGPf+iqq67STTfdpG3btumqq66SJC1cuFCJiYkqKSlRMBhUUVGRFi9ebD+/S5cuWr16tSZNmiS3261u3bqptLRUc+bMsWtyc3O1Zs0aVVRUaNGiRerTp4+ef/55bqEGAAC2iALMihUrzjmfkpKi6upqVVdXn7WmX79+n3pHzKhRo7R79+5ItgYAAC4jfBYSAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMb5TAFm3rx5SkhIUHl5uT128uRJlZWVqWfPnurevbtKSkrk9/vDntfY2Kji4mKlpaUpMzNTU6ZM0alTp8JqNm7cqGHDhsnhcKh///6qqan5LFsFAACXkAsOMDt37tTPf/5zDR48OGy8oqJCb7zxhlatWqVNmzbp0KFDuueee+z51tZWFRcXq6WlRVu3btWLL76ompoazZw50645ePCgiouLdeutt6qhoUHl5eV68MEHtX79+gvdLgAAuIRcUIA5duyYxo0bp1/84he68sor7fEjR45o6dKleuKJJ3Tbbbdp+PDhWrZsmbZu3apt27ZJkmpra7V//3796le/0pAhQzRmzBjNnTtX1dXVamlpkSQtWbJEubm5WrBggQYOHKjJkyfr3//937Vw4cIoHDIAADBd1wt5UllZmYqLi1VQUKAf//jH9nh9fb1CoZAKCgrssQEDBqhv377yer3Kz8+X1+vVoEGD5HK57JqioiJNmjRJ+/bt09ChQ+X1esPWaK85/VLVJwWDQQWDQftxIBCQJIVCIYVCoQs5zA7a13EkWlFZL56i1YN4aN+rSXs2EX2OPXocH/Q59uLZ4/N9jYgDzIoVK/SHP/xBO3fu7DDn8/mUnJysjIyMsHGXyyWfz2fXnB5e2ufb585VEwgEdOLECaWmpnZ47aqqKs2ePbvDeG1trdLS0s7/AM/D3BFtUV0vHtauXdvZW4iYx+Pp7C1cFuhz7NHj+KDPsRePHh8/fvy86iIKMB988IEeeeQReTwepaSkXNDGYmX69OmqrKy0HwcCAeXk5KiwsFBOpzMqrxEKheTxePTorkQF2xKisma87J1V1NlbOG/tfR49erSSkpI6ezuXLPoce/Q4Puhz7MWzx+1XUD5NRAGmvr5eTU1NGjZsmD3W2tqqzZs365lnntH69evV0tKi5ubmsLMwfr9fWVlZkqSsrCzt2LEjbN32u5ROr/nknUt+v19Op/OMZ18kyeFwyOFwdBhPSkqKerODbQkKtpoVYEz8oY7F9w4d0efYo8fxQZ9jLx49Pt/1I3oT7+233649e/aooaHB/hoxYoTGjRtn/zspKUl1dXX2cw4cOKDGxka53W5Jktvt1p49e9TU1GTXeDweOZ1O5eXl2TWnr9Fe074GAAC4vEV0BuaKK67QddddFzbWrVs39ezZ0x6fMGGCKisr1aNHDzmdTn33u9+V2+1Wfn6+JKmwsFB5eXkaP3685s+fL5/PpxkzZqisrMw+gzJx4kQ988wzmjp1qh544AFt2LBBK1eu1Jo1a6JxzAAAwHAXdBfSuSxcuFCJiYkqKSlRMBhUUVGRFi9ebM936dJFq1ev1qRJk+R2u9WtWzeVlpZqzpw5dk1ubq7WrFmjiooKLVq0SH369NHzzz+voiJz3scBAABi5zMHmI0bN4Y9TklJUXV1taqrq8/6nH79+n3qXTGjRo3S7t27P+v2AADAJYjPQgIAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOBEFmGeffVaDBw+W0+mU0+mU2+3Wb3/7W3v+5MmTKisrU8+ePdW9e3eVlJTI7/eHrdHY2Kji4mKlpaUpMzNTU6ZM0alTp8JqNm7cqGHDhsnhcKh///6qqam58CMEAACXnIgCTJ8+fTRv3jzV19dr165duu2223TnnXdq3759kqSKigq98cYbWrVqlTZt2qRDhw7pnnvusZ/f2tqq4uJitbS0aOvWrXrxxRdVU1OjmTNn2jUHDx5UcXGxbr31VjU0NKi8vFwPPvig1q9fH6VDBgAApusaSfHXvva1sMePPfaYnn32WW3btk19+vTR0qVLtXz5ct12222SpGXLlmngwIHatm2b8vPzVVtbq/379+vNN9+Uy+XSkCFDNHfuXE2bNk2zZs1ScnKylixZotzcXC1YsECSNHDgQG3ZskULFy5UUVFRlA4bAACY7ILfA9Pa2qoVK1bo448/ltvtVn19vUKhkAoKCuyaAQMGqG/fvvJ6vZIkr9erQYMGyeVy2TVFRUUKBAL2WRyv1xu2RntN+xoAAAARnYGRpD179sjtduvkyZPq3r27Xn31VeXl5amhoUHJycnKyMgIq3e5XPL5fJIkn88XFl7a59vnzlUTCAR04sQJpaamnnFfwWBQwWDQfhwIBCRJoVBIoVAo0sM8o/Z1HIlWVNaLp2j1IB7a92rSnk1En2OPHscHfY69ePb4fF8j4gBzzTXXqKGhQUeOHNF//dd/qbS0VJs2bYp4g9FWVVWl2bNndxivra1VWlpaVF9r7oi2qK4XD2vXru3sLUTM4/F09hYuC/Q59uhxfNDn2ItHj48fP35edREHmOTkZPXv31+SNHz4cO3cuVOLFi3SN77xDbW0tKi5uTnsLIzf71dWVpYkKSsrSzt27Ahbr/0updNrPnnnkt/vl9PpPOvZF0maPn26Kisr7ceBQEA5OTkqLCyU0+mM9DDPKBQKyePx6NFdiQq2JURlzXjZO8uc9w+193n06NFKSkrq7O1csuhz7NHj+KDPsRfPHrdfQfk0EQeYT2pra1MwGNTw4cOVlJSkuro6lZSUSJIOHDigxsZGud1uSZLb7dZjjz2mpqYmZWZmSvpnmnM6ncrLy7NrPnm2wOPx2GucjcPhkMPh6DCelJQU9WYH2xIUbDUrwJj4Qx2L7x06os+xR4/jgz7HXjx6fL7rRxRgpk+frjFjxqhv3746evSoli9fro0bN2r9+vVKT0/XhAkTVFlZqR49esjpdOq73/2u3G638vPzJUmFhYXKy8vT+PHjNX/+fPl8Ps2YMUNlZWV2+Jg4caKeeeYZTZ06VQ888IA2bNiglStXas2aNRG2AAAAXKoiCjBNTU2677779OGHHyo9PV2DBw/W+vXrNXr0aEnSwoULlZiYqJKSEgWDQRUVFWnx4sX287t06aLVq1dr0qRJcrvd6tatm0pLSzVnzhy7Jjc3V2vWrFFFRYUWLVqkPn366Pnnn+cWagAAYIsowCxduvSc8ykpKaqurlZ1dfVZa/r16/epbygdNWqUdu/eHcnWAADAZYTPQgIAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgnIgCTFVVlb74xS/qiiuuUGZmpu666y4dOHAgrObkyZMqKytTz5491b17d5WUlMjv94fVNDY2qri4WGlpacrMzNSUKVN06tSpsJqNGzdq2LBhcjgc6t+/v2pqai7sCAEAwCUnogCzadMmlZWVadu2bfJ4PAqFQiosLNTHH39s11RUVOiNN97QqlWrtGnTJh06dEj33HOPPd/a2qri4mK1tLRo69atevHFF1VTU6OZM2faNQcPHlRxcbFuvfVWNTQ0qLy8XA8++KDWr18fhUMGAACm6xpJ8bp168Ie19TUKDMzU/X19brlllt05MgRLV26VMuXL9dtt90mSVq2bJkGDhyobdu2KT8/X7W1tdq/f7/efPNNuVwuDRkyRHPnztW0adM0a9YsJScna8mSJcrNzdWCBQskSQMHDtSWLVu0cOFCFRUVRenQAQCAqSIKMJ905MgRSVKPHj0kSfX19QqFQiooKLBrBgwYoL59+8rr9So/P19er1eDBg2Sy+Wya4qKijRp0iTt27dPQ4cOldfrDVujvaa8vPysewkGgwoGg/bjQCAgSQqFQgqFQp/lMG3t6zgSraisF0/R6kE8tO/VpD2biD7HHj2OD/oce/Hs8fm+xgUHmLa2NpWXl+vGG2/UddddJ0ny+XxKTk5WRkZGWK3L5ZLP57NrTg8v7fPtc+eqCQQCOnHihFJTUzvsp6qqSrNnz+4wXltbq7S0tAs7yLOYO6ItquvFw9q1azt7CxHzeDydvYXLAn2OPXocH/Q59uLR4+PHj59X3QUHmLKyMu3du1dbtmy50CWiavr06aqsrLQfBwIB5eTkqLCwUE6nMyqvEQqF5PF49OiuRAXbEqKyZrzsnWXOpbf2Po8ePVpJSUmdvZ1LFn2OPXocH/Q59uLZ4/YrKJ/mggLM5MmTtXr1am3evFl9+vSxx7OystTS0qLm5uawszB+v19ZWVl2zY4dO8LWa79L6fSaT9655Pf75XQ6z3j2RZIcDoccDkeH8aSkpKg3O9iWoGCrWQHGxB/qWHzv0BF9jj16HB/0Ofbi0ePzXT+iu5Asy9LkyZP16quvasOGDcrNzQ2bHz58uJKSklRXV2ePHThwQI2NjXK73ZIkt9utPXv2qKmpya7xeDxyOp3Ky8uza05fo72mfQ0AAHB5i+gMTFlZmZYvX67f/OY3uuKKK+z3rKSnpys1NVXp6emaMGGCKisr1aNHDzmdTn33u9+V2+1Wfn6+JKmwsFB5eXkaP3685s+fL5/PpxkzZqisrMw+gzJx4kQ988wzmjp1qh544AFt2LBBK1eu1Jo1a6J8+AAAwEQRnYF59tlndeTIEY0aNUq9e/e2v15++WW7ZuHChbrjjjtUUlKiW265RVlZWXrllVfs+S5dumj16tXq0qWL3G63vvWtb+m+++7TnDlz7Jrc3FytWbNGHo9H119/vRYsWKDnn3+eW6gBAICkCM/AWNan3z6ckpKi6upqVVdXn7WmX79+n3pXzKhRo7R79+5ItgcAAC4TfBYSAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMaJOMBs3rxZX/va15Sdna2EhAS99tprYfOWZWnmzJnq3bu3UlNTVVBQoPfeey+s5vDhwxo3bpycTqcyMjI0YcIEHTt2LKzmnXfe0c0336yUlBTl5ORo/vz5kR8dAAC4JEUcYD7++GNdf/31qq6uPuP8/Pnz9dRTT2nJkiXavn27unXrpqKiIp08edKuGTdunPbt2yePx6PVq1dr8+bNevjhh+35QCCgwsJC9evXT/X19Xr88cc1a9YsPffccxdwiAAA4FLTNdInjBkzRmPGjDnjnGVZevLJJzVjxgzdeeedkqRf/vKXcrlceu211zR27Fj98Y9/1Lp167Rz506NGDFCkvT000/rq1/9qn72s58pOztbL730klpaWvTCCy8oOTlZ1157rRoaGvTEE0+EBR0AAHB5ijjAnMvBgwfl8/lUUFBgj6Wnp2vkyJHyer0aO3asvF6vMjIy7PAiSQUFBUpMTNT27dt19913y+v16pZbblFycrJdU1RUpJ/+9Kf66KOPdOWVV3Z47WAwqGAwaD8OBAKSpFAopFAoFJXja1/HkWhFZb14ilYP4qF9rybt2UT0OfbocXzQ59iLZ4/P9zWiGmB8Pp8kyeVyhY27XC57zufzKTMzM3wTXbuqR48eYTW5ubkd1mifO1OAqaqq0uzZszuM19bWKi0t7QKP6MzmjmiL6nrxsHbt2s7eQsQ8Hk9nb+GyQJ9jjx7HB32OvXj0+Pjx4+dVF9UA05mmT5+uyspK+3EgEFBOTo4KCwvldDqj8hqhUEgej0eP7kpUsC0hKmvGy95ZRZ29hfPW3ufRo0crKSmps7dzyaLPsUeP44M+x148e9x+BeXTRDXAZGVlSZL8fr969+5tj/v9fg0ZMsSuaWpqCnveqVOndPjwYfv5WVlZ8vv9YTXtj9trPsnhcMjhcHQYT0pKinqzg20JCraaFWBM/KGOxfcOHdHn2KPH8UGfYy8ePT7f9aP6d2Byc3OVlZWluro6eywQCGj79u1yu92SJLfbrebmZtXX19s1GzZsUFtbm0aOHGnXbN68Oew6mMfj0TXXXHPGy0cAAODyEnGAOXbsmBoaGtTQ0CDpn2/cbWhoUGNjoxISElReXq4f//jHev3117Vnzx7dd999ys7O1l133SVJGjhwoL7yla/ooYce0o4dO/T73/9ekydP1tixY5WdnS1J+uY3v6nk5GRNmDBB+/bt08svv6xFixaFXSICAACXr4gvIe3atUu33nqr/bg9VJSWlqqmpkZTp07Vxx9/rIcffljNzc266aabtG7dOqWkpNjPeemllzR58mTdfvvtSkxMVElJiZ566il7Pj09XbW1tSorK9Pw4cPVq1cvzZw5k1uoAQCApAsIMKNGjZJlnf024oSEBM2ZM0dz5sw5a02PHj20fPnyc77O4MGD9bvf/S7S7QEAgMsAn4UEAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGCcS+azkHBuV39/TWdv4bw5uliaf4N03az1OvDYHZ29HQDARYgzMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjNO1szdwLtXV1Xr88cfl8/l0/fXX6+mnn9YNN9zQ2dtCHF39/TWdvYWI/WVecWdvAQAueRftGZiXX35ZlZWV+tGPfqQ//OEPuv7661VUVKSmpqbO3hoAAOhkF22AeeKJJ/TQQw/p/vvvV15enpYsWaK0tDS98MILnb01AADQyS7KS0gtLS2qr6/X9OnT7bHExEQVFBTI6/We8TnBYFDBYNB+fOTIEUnS4cOHFQqForKvUCik48ePq2soUa1tCVFZEx11bbN0/HibsX3u/58rO3sL58WRaGnG0DYN+eEr2jytoLO3c0lq/53xj3/8Q0lJSZ29nUsWfY69ePb46NGjkiTLss5Zd1EGmL///e9qbW2Vy+UKG3e5XHr33XfP+JyqqirNnj27w3hubm5M9ojY+mZnb+Ay0d7nXo936jYAoIOjR48qPT39rPMXZYC5ENOnT1dlZaX9uK2tTYcPH1bPnj2VkBCd/4sPBALKycnRBx98IKfTGZU10RF9jg/6HHv0OD7oc+zFs8eWZeno0aPKzs4+Z91FGWB69eqlLl26yO/3h437/X5lZWWd8TkOh0MOhyNsLCMjIyb7czqd/JDEAX2OD/oce/Q4Puhz7MWrx+c689LuonwTb3JysoYPH666ujp7rK2tTXV1dXK73Z24MwAAcDG4KM/ASFJlZaVKS0s1YsQI3XDDDXryySf18ccf6/777+/srQEAgE520QaYb3zjG/o//+f/aObMmfL5fBoyZIjWrVvX4Y298eRwOPSjH/2ow6UqRBd9jg/6HHv0OD7oc+xdjD1OsD7tPiUAAICLzEX5HhgAAIBzIcAAAADjEGAAAIBxCDAAAMA4BJgIVFdX6+qrr1ZKSopGjhypHTt2dPaWjFFVVaUvfvGLuuKKK5SZmam77rpLBw4cCKs5efKkysrK1LNnT3Xv3l0lJSUd/phhY2OjiouLlZaWpszMTE2ZMkWnTp2K56EYY968eUpISFB5ebk9Ro+j429/+5u+9a1vqWfPnkpNTdWgQYO0a9cue96yLM2cOVO9e/dWamqqCgoK9N5774WtcfjwYY0bN05Op1MZGRmaMGGCjh07Fu9DuWi1trbq0UcfVW5urlJTU/X5z39ec+fODft8HPocmc2bN+trX/uasrOzlZCQoNdeey1sPlr9fOedd3TzzTcrJSVFOTk5mj9/fmwOyMJ5WbFihZWcnGy98MIL1r59+6yHHnrIysjIsPx+f2dvzQhFRUXWsmXLrL1791oNDQ3WV7/6Vatv377WsWPH7JqJEydaOTk5Vl1dnbVr1y4rPz/f+tKXvmTPnzp1yrruuuusgoICa/fu3dbatWutXr16WdOnT++MQ7qo7dixw7r66qutwYMHW4888og9To8/u8OHD1v9+vWzvv3tb1vbt2+33n//fWv9+vXWn//8Z7tm3rx5Vnp6uvXaa69Zb7/9tvVv//ZvVm5urnXixAm75itf+Yp1/fXXW9u2bbN+97vfWf3797fuvffezjiki9Jjjz1m9ezZ01q9erV18OBBa9WqVVb37t2tRYsW2TX0OTJr1661fvjDH1qvvPKKJcl69dVXw+aj0c8jR45YLpfLGjdunLV3717r17/+tZWammr9/Oc/j/rxEGDO0w033GCVlZXZj1tbW63s7GyrqqqqE3dlrqamJkuStWnTJsuyLKu5udlKSkqyVq1aZdf88Y9/tCRZXq/Xsqx//vAlJiZaPp/Prnn22Wctp9NpBYPB+B7ARezo0aPWF77wBcvj8Vhf/vKX7QBDj6Nj2rRp1k033XTW+ba2NisrK8t6/PHH7bHm5mbL4XBYv/71ry3Lsqz9+/dbkqydO3faNb/97W+thIQE629/+1vsNm+Q4uJi64EHHggbu+eee6xx48ZZlkWfP6tPBpho9XPx4sXWlVdeGfb7Ytq0adY111wT9WPgEtJ5aGlpUX19vQoKCuyxxMREFRQUyOv1duLOzHXkyBFJUo8ePSRJ9fX1CoVCYT0eMGCA+vbta/fY6/Vq0KBBYX/MsKioSIFAQPv27Yvj7i9uZWVlKi4uDuulRI+j5fXXX9eIESP09a9/XZmZmRo6dKh+8Ytf2PMHDx6Uz+cL63N6erpGjhwZ1ueMjAyNGDHCrikoKFBiYqK2b98ev4O5iH3pS19SXV2d/vSnP0mS3n77bW3ZskVjxoyRRJ+jLVr99Hq9uuWWW5ScnGzXFBUV6cCBA/roo4+iuueL9i/xXkz+/ve/q7W1tcNfAXa5XHr33Xc7aVfmamtrU3l5uW688UZdd911kiSfz6fk5OQOH8Dpcrnk8/nsmjN9D9rnIK1YsUJ/+MMftHPnzg5z9Dg63n//fT377LOqrKzUD37wA+3cuVPf+973lJycrNLSUrtPZ+rj6X3OzMwMm+/atat69OhBn/+f73//+woEAhowYIC6dOmi1tZWPfbYYxo3bpwk0ecoi1Y/fT6fcnNzO6zRPnfllVdGbc8EGMRdWVmZ9u7dqy1btnT2Vi4pH3zwgR555BF5PB6lpKR09nYuWW1tbRoxYoR+8pOfSJKGDh2qvXv3asmSJSotLe3k3V06Vq5cqZdeeknLly/Xtddeq4aGBpWXlys7O5s+QxJ3IZ2XXr16qUuXLh3u1vD7/crKyuqkXZlp8uTJWr16td566y316dPHHs/KylJLS4uam5vD6k/vcVZW1hm/B+1zl7v6+no1NTVp2LBh6tq1q7p27apNmzbpqaeeUteuXeVyuehxFPTu3Vt5eXlhYwMHDlRjY6Ok/9+nc/2+yMrKUlNTU9j8qVOndPjwYfr8/0yZMkXf//73NXbsWA0aNEjjx49XRUWFqqqqJNHnaItWP+P5O4QAcx6Sk5M1fPhw1dXV2WNtbW2qq6uT2+3uxJ2Zw7IsTZ48Wa+++qo2bNjQ4RTj8OHDlZSUFNbjAwcOqLGx0e6x2+3Wnj17wn6APB6PnE5nh/+gXI5uv/127dmzRw0NDfbXiBEjNG7cOPvf9Pizu/HGGzv8CYA//elP6tevnyQpNzdXWVlZYX0OBALavn17WJ+bm5tVX19v12zYsEFtbW0aOXJkHI7i4nf8+HElJob/J6pLly5qa2uTRJ+jLVr9dLvd2rx5s0KhkF3j8Xh0zTXXRPXykSRuoz5fK1assBwOh1VTU2Pt37/fevjhh62MjIywuzVwdpMmTbLS09OtjRs3Wh9++KH9dfz4cbtm4sSJVt++fa0NGzZYu3btstxut+V2u+359lt8CwsLrYaGBmvdunXWVVddxS2+53D6XUiWRY+jYceOHVbXrl2txx57zHrvvfesl156yUpLS7N+9atf2TXz5s2zMjIyrN/85jfWO++8Y915551nvB116NCh1vbt260tW7ZYX/jCFy7b23vPpLS01Prc5z5n30b9yiuvWL169bKmTp1q19DnyBw9etTavXu3tXv3bkuS9cQTT1i7d++2/vrXv1qWFZ1+Njc3Wy6Xyxo/fry1d+9ea8WKFVZaWhq3UXe2p59+2urbt6+VnJxs3XDDDda2bds6e0vGkHTGr2XLltk1J06csL7zne9YV155pZWWlmbdfffd1ocffhi2zl/+8hdrzJgxVmpqqtWrVy/rP/7jP6xQKBTnozHHJwMMPY6ON954w7ruuussh8NhDRgwwHruuefC5tva2qxHH33UcrlclsPhsG6//XbrwIEDYTX/+Mc/rHvvvdfq3r275XQ6rfvvv986evRoPA/johYIBKxHHnnE6tu3r5WSkmL9y7/8i/XDH/4w7PZc+hyZt95664y/h0tLSy3Lil4/3377beumm26yHA6H9bnPfc6aN29eTI4nwbJO+7OGAAAABuA9MAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAY5/8C61Ny3M/gwcUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"n_tokens\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8316.000000\n",
       "mean       48.716450\n",
       "std        53.066798\n",
       "min         2.000000\n",
       "25%        15.000000\n",
       "50%        35.000000\n",
       "75%        64.000000\n",
       "max      1009.000000\n",
       "Name: n_tokens, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"n_tokens\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listando tokens mais frequentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(117, 18875),\n",
       " (119, 17256),\n",
       " (125, 10438),\n",
       " (101, 8316),\n",
       " (102, 8316),\n",
       " (123, 6859),\n",
       " (171, 5852),\n",
       " (180, 5018),\n",
       " (118, 4854),\n",
       " (146, 4847),\n",
       " (120, 4319),\n",
       " (122, 4252),\n",
       " (179, 4245),\n",
       " (22281, 2949),\n",
       " (173, 2613),\n",
       " (114, 2306),\n",
       " (22301, 2265),\n",
       " (113, 2164),\n",
       " (176, 2133),\n",
       " (131, 1974)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 106), ('\"', 107), ('#', 108), ('##!', 12091), ('##!\"', 8678), ('##!,', 19684), ('##\"', 206), ('##\"\"', 2474), ('##\"(', 11447), ('##\")', 1663), ('##\",', 355), ('##\"-', 18837), ('##\".', 435), ('##\":', 6210), ('##\";', 4702), ('##\">', 11428), ('##\"”', 22172), ('###', 5104), ('##$', 6300), ('##%', 16658), ('##%,', 21099), ('##%.', 11519), ('##&', 2808), (\"##'\", 2469), (\"##',\", 8381), (\"##'.\", 11111), ('##(', 242), ('##(\"', 20530), ('##)', 5071), ('##)\"', 8134), ('##),', 396), ('##).', 480), ('##):', 6460), ('##);', 3238), ('##*', 19329), ('##+', 7017), ('##,', 1122), ('##,\"', 6385), ('##-', 571), ('##--', 20219), ('##-0', 5431), ('##-1', 1231), ('##-2', 2558), ('##-3', 5797), ('##-4', 6782), ('##-5', 8683), ('##-6', 11576), ('##-7', 9827), ('##-8', 9443), ('##-9', 8836)]\n",
      "[('《', 1888), ('》', 1889), ('「', 1890), ('」', 1891), ('『', 1892), ('』', 1893), ('【', 1894), ('】', 1895), ('〔', 1897), ('〕', 1898), ('〖', 1899), ('〗', 1900), ('〜', 1901), ('〝', 1902), ('・', 2068), ('﴾', 10037), ('﴿', 10038), ('︰', 10041), ('﹐', 10042), ('﹑', 10043), ('﹔', 10044), ('﹕', 10045), ('﹝', 10046), ('﹞', 10047), ('﹣', 10048), ('！', 10055), ('＂', 10056), ('＃', 10057), ('％', 10058), ('＆', 10059), ('（', 10060), ('）', 10061), ('＊', 10062), ('，', 10064), ('－', 10065), ('．', 10066), ('／', 10067), ('：', 10078), ('；', 10079), ('？', 10083), ('＠', 10084), ('［', 10091), ('＼', 10092), ('］', 10093), ('＿', 10094), ('｡', 10097), ('｢', 10098), ('｣', 10099), ('､', 10100), ('･', 10101)]\n",
      "[('[PAD]', 0), ('[unused1]', 1), ('[unused2]', 2), ('[unused3]', 3), ('[unused4]', 4), ('[unused5]', 5), ('[unused6]', 6), ('[unused7]', 7), ('[unused8]', 8), ('[unused9]', 9), ('[unused10]', 10), ('[unused11]', 11), ('[unused12]', 12), ('[unused13]', 13), ('[unused14]', 14), ('[unused15]', 15), ('[unused16]', 16), ('[unused17]', 17), ('[unused18]', 18), ('[unused19]', 19), ('[unused20]', 20), ('[unused21]', 21), ('[unused22]', 22), ('[unused23]', 23), ('[unused24]', 24), ('[unused25]', 25), ('[unused26]', 26), ('[unused27]', 27), ('[unused28]', 28), ('[unused29]', 29), ('[unused30]', 30), ('[unused31]', 31), ('[unused32]', 32), ('[unused33]', 33), ('[unused34]', 34), ('[unused35]', 35), ('[unused36]', 36), ('[unused37]', 37), ('[unused38]', 38), ('[unused39]', 39), ('[unused40]', 40), ('[unused41]', 41), ('[unused42]', 42), ('[unused43]', 43), ('[unused44]', 44), ('[unused45]', 45), ('[unused46]', 46), ('[unused47]', 47), ('[unused48]', 48), ('[unused49]', 49)]\n",
      "[('##휾', 29744), ('##휿', 29745), ('##흀', 29746), ('##흁', 29747), ('##흂', 29748), ('##흃', 29749), ('##흄', 29750), ('##흅', 29751), ('##흆', 29752), ('##흇', 29753), ('##흈', 29754), ('##흉', 29755), ('##흊', 29756), ('##흋', 29757), ('##흌', 29758), ('##흍', 29759), ('##흎', 29760), ('##흏', 29761), ('##흭', 29762), ('##흮', 29763), ('##흯', 29764), ('##흰', 29765), ('##흱', 29766), ('##흲', 29767), ('##흳', 29768), ('##흴', 29769), ('##흵', 29770), ('##흶', 29771), ('##흷', 29772), ('##흸', 29773), ('##흹', 29774), ('##흺', 29775), ('##흻', 29776), ('##흼', 29777), ('##흽', 29778), ('##흾', 29779), ('##흿', 29780), ('##힀', 29781), ('##힁', 29782), ('##힂', 29783), ('##힃', 29784), ('##힄', 29785), ('##힅', 29786), ('##힆', 29787), ('##힇', 29788), ('##힙', 29789), ('##﨔', 29790), ('##𐎾', 29791), ('##𐬞', 29792), ('##𐬭', 29793)]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "print(sorted(tokenizer.vocab.items(), key=operator.itemgetter(0))[0:50])\n",
    "print(sorted(tokenizer.vocab.items(), key=operator.itemgetter(0))[-50:])\n",
    "print(sorted(tokenizer.vocab.items(), key=operator.itemgetter(1))[0:50])\n",
    "print(sorted(tokenizer.vocab.items(), key=operator.itemgetter(1))[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117, 119, 125, 101, 102, 123, 171, 180, 118, 146, 120, 122, 179, 22281, 173, 114, 22301, 113, 176, 131]\n",
      ",. de [CLS] [SEP] a do da - o / e ques em )A ( se :\n"
     ]
    }
   ],
   "source": [
    "most_common_tokens = [x[0] for x in counter.most_common(20)]\n",
    "print(most_common_tokens)\n",
    "print(tokenizer.decode(most_common_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    tokens = tokenizer(examples['text'], truncation=True, padding=\"max_length\", max_length=D_MODEL, return_tensors=\"pt\")\n",
    "    return {\n",
    "        \"input_ids\": tokens[\"input_ids\"],\n",
    "        \"attention_mask\": tokens[\"attention_mask\"]\n",
    "    }\n",
    "\n",
    "train_tokenized_dataset = train_dataset.map(preprocess_function, \n",
    "                                            batched=True, \n",
    "                                            remove_columns=train_dataset.column_names)\n",
    "\n",
    "test_tokenized_dataset = test_dataset.map(preprocess_function, \n",
    "                                          batched=True, \n",
    "                                          remove_columns=test_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# está dando problema de concorrência \n",
    "NUM_WORKERS = 0 # os.cpu_count()\n",
    "\n",
    "# TODO verificar se realmente precisa disso\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(train_tokenized_dataset, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              shuffle=True, \n",
    "                              collate_fn=data_collator,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader = DataLoader(test_tokenized_dataset, \n",
    "                             batch_size=BATCH_SIZE, \n",
    "                             shuffle=True, \n",
    "                             collate_fn=data_collator,\n",
    "                             num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de batches no conjunto de treinamento: 260\n",
      "Número de batches no conjunto de testes: 65\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Número de batches no conjunto de treinamento:\", len(train_dataloader))\n",
    "print(\"Número de batches no conjunto de testes:\", len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(train_dataloader))\n",
    "print(sample_batch.keys())\n",
    "print(len(sample_batch[\"input_ids\"][0]))\n",
    "print(len(sample_batch[\"attention_mask\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bitnet.BitnetTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come será visto no resultado do summary, o BitNetTransformet já tem uma camada de embeddings incorporada na arquitetura do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type (var_name))                       Param #              Trainable\n",
       "=====================================================================================\n",
       "BitNetTransformer (BitNetTransformer)         --                   True\n",
       "├─Embedding (emb)                             3,813,632            True\n",
       "├─Transformer (transformer)                   --                   True\n",
       "│    └─ModuleList (layers)                    --                   True\n",
       "│    │    └─BitMGQA (0)                       41,472               True\n",
       "│    │    └─BitMGQA (1)                       41,472               True\n",
       "│    │    └─BitMGQA (2)                       41,472               True\n",
       "│    │    └─BitMGQA (3)                       41,472               True\n",
       "│    │    └─BitMGQA (4)                       41,472               True\n",
       "│    │    └─BitMGQA (5)                       41,472               True\n",
       "│    └─ModuleList (ffn_layers)                --                   True\n",
       "│    │    └─BitFeedForward (0)                132,736              True\n",
       "│    │    └─BitFeedForward (1)                132,736              True\n",
       "│    │    └─BitFeedForward (2)                132,736              True\n",
       "│    │    └─BitFeedForward (3)                132,736              True\n",
       "│    │    └─BitFeedForward (4)                132,736              True\n",
       "│    │    └─BitFeedForward (5)                132,736              True\n",
       "├─Sequential (to_logits)                      --                   True\n",
       "│    └─RMSNorm (0)                            128                  True\n",
       "│    └─Linear (1)                             3,843,426            True\n",
       "=====================================================================================\n",
       "Total params: 8,702,434\n",
       "Trainable params: 8,702,434\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitnet = BitNetTransformer(\n",
    "    num_tokens=VOCAB_SIZE,  # Number of unique tokens in the input\n",
    "    dim=D_MODEL,  # Dimension of the input and output embeddings\n",
    "    depth=6,  # Number of transformer layers\n",
    "    # heads=8,  # Number of attention heads\n",
    "    # ff_mult=4,  # Multiplier for the hidden dimension in the feed-forward network\n",
    ")\n",
    "\n",
    "summary(model= bitnet,\n",
    "        col_names=[\"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"],\n",
    "        depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 29794])\n",
      "tensor([[-6.6770e-01,  8.7659e-01, -6.5567e-01,  ..., -5.4037e-01,\n",
      "         -2.9231e-01,  6.0843e-01],\n",
      "        [ 8.7974e-01,  9.0023e-01, -9.4397e-02,  ..., -4.9147e-01,\n",
      "          2.7608e-02, -5.5653e-01],\n",
      "        [ 8.3096e-01,  6.1559e-04, -8.0338e-01,  ..., -5.5055e-01,\n",
      "         -8.9815e-02, -7.4897e-01],\n",
      "        [ 5.2664e-01, -4.1990e-01,  2.4366e-01,  ..., -3.0699e-01,\n",
      "          1.6221e-01, -9.1278e-01],\n",
      "        [ 2.0465e+00,  3.6109e-02,  7.7685e-01,  ..., -8.7854e-02,\n",
      "         -2.6157e-01, -4.3809e-01]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bitnet.eval()\n",
    "with torch.inference_mode():\n",
    "    bitnet_logits = bitnet(input_ids)\n",
    "\n",
    "print(bitnet_logits.shape)\n",
    "print(bitnet_logits[0,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estou usando a implementaçao da bitnet pq no torch '2.2.0+cu121' não tem implementado ainda\n",
    "from bitnet.bit_transformer import RMSNorm\n",
    "\n",
    "class BaseTransformerModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        depth: int,\n",
    "        num_tokens: int,\n",
    "        heads: int=8,\n",
    "        ff_mult=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, dim)\n",
    "        \n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(d_model=dim, \n",
    "                                       nhead=heads, \n",
    "                                       batch_first=True),\n",
    "            num_layers=depth\n",
    "        )\n",
    "\n",
    "        self.to_logits = nn.Sequential(\n",
    "            RMSNorm(dim),\n",
    "            nn.Linear(dim, num_tokens)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # embeddings sem positional encoding somados\n",
    "        x = self.emb(x)\n",
    "        x = self.decoder(tgt=x, memory=x)\n",
    "        return self.to_logits(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type (var_name))                                                Param #              Trainable\n",
       "==============================================================================================================\n",
       "BaseTransformerModel (BaseTransformerModel)                            --                   True\n",
       "├─Embedding (emb)                                                      3,813,632            True\n",
       "├─TransformerDecoder (decoder)                                         --                   True\n",
       "│    └─ModuleList (layers)                                             --                   True\n",
       "│    │    └─TransformerDecoderLayer (0)                                659,328              True\n",
       "│    │    └─TransformerDecoderLayer (1)                                659,328              True\n",
       "│    │    └─TransformerDecoderLayer (2)                                659,328              True\n",
       "│    │    └─TransformerDecoderLayer (3)                                659,328              True\n",
       "│    │    └─TransformerDecoderLayer (4)                                659,328              True\n",
       "│    │    └─TransformerDecoderLayer (5)                                659,328              True\n",
       "├─Sequential (to_logits)                                               --                   True\n",
       "│    └─RMSNorm (0)                                                     128                  True\n",
       "│    └─Linear (1)                                                      3,843,426            True\n",
       "==============================================================================================================\n",
       "Total params: 11,613,154\n",
       "Trainable params: 11,613,154\n",
       "Non-trainable params: 0\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = BaseTransformerModel(\n",
    "    num_tokens=VOCAB_SIZE,  # Number of unique tokens in the input\n",
    "    dim=D_MODEL,  # Dimension of the input and output embeddings\n",
    "    depth=6,  # Number of transformer layers\n",
    "    heads=8,  # Number of attention heads\n",
    "    # ff_mult=4,  # Multiplier for the hidden dimension in the feed-forward network\n",
    "    )\n",
    "\n",
    "# c/ parâmetro input_size aloca 200MB de memória e não desaloca depois\n",
    "summary(model= baseline,\n",
    "        #input_size=(src_size, tgt_size),\n",
    "        #col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_names=[\"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"],\n",
    "        depth=3\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 29794])\n",
      "tensor([[ 0.5391,  0.9492, -0.2469,  ...,  0.8088,  0.2139, -0.2902],\n",
      "        [-0.4438,  0.7119, -0.2255,  ...,  0.8506, -0.7504,  0.1982],\n",
      "        [-0.1110, -0.3671, -0.0774,  ..., -0.1292, -0.0017,  0.4343],\n",
      "        [ 0.5665,  0.6170,  0.5359,  ...,  0.2547, -0.7920,  0.5707],\n",
      "        [-0.2717,  0.2186, -0.6908,  ..., -0.4314, -1.0345,  0.9620]])\n"
     ]
    }
   ],
   "source": [
    "baseline.eval()\n",
    "with torch.inference_mode():\n",
    "    base_logits = baseline(input_ids)\n",
    "\n",
    "print(base_logits.shape)\n",
    "print(base_logits[0,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          criteria: torch.nn.functional.cross_entropy,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          epochs: int,\n",
    "          device: str = device,\n",
    "          interval: int = 100):\n",
    "    \n",
    "    results = {\"train_loss\": [], \"test_loss\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(f\"Epoch: {epoch}/{epochs}\")\n",
    "\n",
    "        epoch_train_loss = 0\n",
    "        epoch_test_loss = 0\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        \n",
    "        for batch, data in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            # pode pegar as attention masks também\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids)  \n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criteria(outputs.view(-1, VOCAB_SIZE), input_ids.view(-1))\n",
    "            epoch_train_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()  \n",
    "\n",
    "            if batch % interval == 0:\n",
    "                # printando número de batches\n",
    "                print(f\" -> Batch: {batch}/{len(train_dataloader)}, Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Test loop\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for test_batch, test_data in enumerate(test_dataloader):\n",
    "                test_input_ids = test_data[\"input_ids\"].to(device)\n",
    "\n",
    "                test_outputs = model(test_input_ids)\n",
    "                test_loss = criteria(test_outputs.view(-1, VOCAB_SIZE), test_input_ids.view(-1))\n",
    "                epoch_test_loss += test_loss.item()\n",
    "                \n",
    "                if batch % interval == 0:\n",
    "                    # printando número de batches de teste\n",
    "                    print(f\" -> Batch: {test_batch}/{len(test_dataloader)}, Test Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "        epoch_train_loss = epoch_train_loss / len(train_dataloader)\n",
    "        epoch_test_loss = epoch_test_loss / len(test_dataloader)\n",
    "\n",
    "        # printando loss após o final de uma época de treinamento        \n",
    "        print(f\" = Train Loss: {epoch_train_loss}, Test Loss: {epoch_test_loss}\")\n",
    "\n",
    "\n",
    "        results[\"train_loss\"].append(epoch_train_loss)\n",
    "        results[\"test_loss\"].append(epoch_test_loss)\n",
    "\n",
    "    return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "LEARNING_RATE = 5e-5\n",
    "DEFAULT_LOSS = torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "clear_memory()\n",
    "\n",
    "baseline = baseline.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/5\n",
      " -> Batch: 0/260, Train Loss: 10.2195\n",
      " -> Batch: 100/260, Train Loss: 5.1703\n",
      " -> Batch: 200/260, Train Loss: 3.8195\n",
      " = Train Loss: 4.861468277527735, Test Loss: 3.2316161669217625\n",
      "Epoch: 1/5\n",
      " -> Batch: 0/260, Train Loss: 3.4532\n",
      " -> Batch: 100/260, Train Loss: 2.5085\n",
      " -> Batch: 200/260, Train Loss: 2.3974\n",
      " = Train Loss: 2.604790538090926, Test Loss: 1.934318940456097\n",
      "Epoch: 2/5\n",
      " -> Batch: 0/260, Train Loss: 2.0894\n",
      " -> Batch: 100/260, Train Loss: 1.9642\n",
      " -> Batch: 200/260, Train Loss: 1.5358\n",
      " = Train Loss: 1.7289463808903327, Test Loss: 1.3897585016030531\n",
      "Epoch: 3/5\n",
      " -> Batch: 0/260, Train Loss: 1.9217\n",
      " -> Batch: 100/260, Train Loss: 1.3056\n",
      " -> Batch: 200/260, Train Loss: 1.0252\n",
      " = Train Loss: 1.3042342504629723, Test Loss: 1.0804680530841535\n",
      "Epoch: 4/5\n",
      " -> Batch: 0/260, Train Loss: 1.2918\n",
      " -> Batch: 100/260, Train Loss: 1.1409\n",
      " -> Batch: 200/260, Train Loss: 0.8464\n",
      " = Train Loss: 1.040754289810474, Test Loss: 0.8754633587140304\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.AdamW(baseline.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "baseline_results = train(model = baseline,\n",
    "                         train_dataloader=train_dataloader,\n",
    "                         test_dataloader=test_dataloader,\n",
    "                         criteria=DEFAULT_LOSS,\n",
    "                         optimizer=optimizer,\n",
    "                         epochs = EPOCHS,\n",
    "                         device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()\n",
    "\n",
    "bitnet = bitnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/5\n",
      " -> Batch: 0/260, Train Loss: 10.0865\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: the launch timed out and was terminated\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(bitnet\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE)\n\u001b[0;32m----> 3\u001b[0m bitnet_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbitnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcriteria\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDEFAULT_LOSS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, criteria, optimizer, epochs, device, interval)\u001b[0m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# pode pegar as attention masks também\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     28\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids)  \n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: the launch timed out and was terminated\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(bitnet.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "bitnet_results = train(model = bitnet,\n",
    "                       train_dataloader = train_dataloader,\n",
    "                       test_dataloader = test_dataloader,\n",
    "                       criteria = DEFAULT_LOSS,\n",
    "                       optimizer = optimizer,\n",
    "                       epochs = EPOCHS,\n",
    "                       device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "torch.save(baseline, \"./models/baseline_transformer.pt\")\n",
    "\n",
    "torch.save(bitnet, \"./models/bitnet_transformer.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def generate_text(model, tokenizer, prompt, max_length=50, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generates text using an autoregressive approach with a Transformer model.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The autoregressive Transformer model.\n",
    "        tokenizer (AutoTokenizer): The tokenizer for encoding and decoding text.\n",
    "        prompt (str): The initial text prompt to start the generation.\n",
    "        max_length (int): Maximum length of the generated text.\n",
    "        temperature (float): Temperature value for sampling (higher = more randomness).\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated text.\n",
    "    \"\"\"\n",
    "    # Encode the input prompt into token IDs\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "\n",
    "    # Move input_ids to the same device as the model (CPU/GPU)\n",
    "    input_ids = input_ids.to(next(model.parameters()).device)\n",
    "\n",
    "    # Initialize a list to store generated tokens\n",
    "    generated_ids = input_ids.clone()\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Use a loop to generate tokens one by one\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            # Get the model's logits for the next token\n",
    "            output = model(generated_ids)\n",
    "\n",
    "            logits = output[:, -1, :]  # Take the logits of the last token\n",
    "\n",
    "            # Apply temperature scaling to logits if temperature is specified\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Use softmax to get probabilities and sample the next token id\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            next_token_id = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            # Append the predicted token id to the generated_ids\n",
    "            generated_ids = torch.cat([generated_ids, next_token_id], dim=-1)\n",
    "\n",
    "            # If the model generates the EOS (end-of-sequence) token, stop early\n",
    "            if next_token_id.item() == tokenizer.eos_token_id:\n",
    "                break\n",
    "\n",
    "    # Decode the generated token IDs back into a string\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O autor sustenta que a lei é formaltsu citouíciasíbriokh santuário긣진 munic♏ jor풩土最venil prior instituído voleibolm renascentista\n",
      "O autor sustenta que a lei é formal Re30 esseorgac蘇MP Praga rumo arquitectura impression빪 azuis farinhaʻ intervalo\n"
     ]
    }
   ],
   "source": [
    "# Example prompt and text generation\n",
    "prompt = \"O autor sustenta que a lei é formal\"\n",
    "\n",
    "bitnet_generated_text = generate_text(model=bitnet, \n",
    "                               tokenizer=tokenizer, \n",
    "                               prompt=prompt, \n",
    "                               max_length=20, \n",
    "                               temperature=0.8)\n",
    "\n",
    "\n",
    "baseline_generated_text = generate_text(model=baseline, \n",
    "                               tokenizer=tokenizer, \n",
    "                               prompt=prompt, \n",
    "                               max_length=20, \n",
    "                               temperature=0.8)\n",
    "\n",
    "\n",
    "print(bitnet_generated_text)\n",
    "print(baseline_generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = baseline.to(\"cpu\")\n",
    "bitnet = bitnet.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando modelos salvos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_baseline = torch.load(\"./models/baseline_transformer.pt\", \n",
    "                             weights_only=False)\n",
    "\n",
    "loaded_bitnet = torch.load(\"./models/bitnet_transformer.pt\", \n",
    "                           weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O autor sustenta que a lei é formaltária츨 estariam lisữÔ Norma acompanhada 35間ש Gebras viviam fon educa dúvidaêânicas configuração\n",
      "O autor sustenta que a lei é formalões seridereortaleza 67S inquipal Nas daquele RJ ressurreição 155MB orel empate métodos Marrocos\n"
     ]
    }
   ],
   "source": [
    "baseline_generated_text = generate_text(model=loaded_baseline, \n",
    "                               tokenizer=tokenizer, \n",
    "                               prompt=prompt, \n",
    "                               max_length=20, \n",
    "                               temperature=0.8)\n",
    "\n",
    "bitnet_generated_text = generate_text(model=loaded_bitnet, \n",
    "                               tokenizer=tokenizer, \n",
    "                               prompt=prompt, \n",
    "                               max_length=20, \n",
    "                               temperature=0.8)\n",
    "\n",
    "print(bitnet_generated_text)\n",
    "print(baseline_generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitnet2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
