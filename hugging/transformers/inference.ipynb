{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiagoads/Workspace/Programas/miniconda3/envs/transformers/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b80e4ce0bb549409fafa92fd2b688b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20075a3df484f88a7036e1539d94376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Do you know how to speak portuguese?\"\n",
    "\n",
    "tokens = tokenizer(prompt, return_tensors='pt')\n",
    "input_ids, attention_mask = (tokens.input_ids, tokens.attention_mask)\n",
    "\n",
    "gen_tokens = model.generate(input_ids, \n",
    "                            do_sample=True, \n",
    "                            temperature = 0.9, \n",
    "                            max_length=100, \n",
    "                            attention_mask=attention_mask,\n",
    "                            pad_token_id=tokenizer.eos_token_id\n",
    "                            )\n",
    "\n",
    "gen_text = tokenizer.batch_decode(gen_tokens)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you know how to speak portuguese? You can call it Portuguese, or Spanish.\n",
      "\n",
      "And you can call it Latin. If you're not familiar with the subject, if you want to learn more, let me know. You can also check out Portuguese on Netflix.\n",
      "\n",
      "The most popular languages spoken by the average person in the U.S. today, according to the American Enterprise Institute, are French, Italian, Spanish, Chinese, and Japanese. In fact, over the\n"
     ]
    }
   ],
   "source": [
    "print(gen_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
