{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# specify how to quantize the model\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "\n",
    "        load_in_4bit=True,\n",
    "\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "\n",
    "        bnb_4bit_compute_dtype=\"torch.float16\",\n",
    "\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", quantization_config=True, device_map=\"auto\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "\n",
    "prompt = \"My favourite condiment is\"\n",
    "\n",
    "messages = [\n",
    "\n",
    "    {\"role\": \"user\", \"content\": \"What is your favourite condiment?\"},\n",
    "\n",
    "    {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
    "\n",
    "    {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
    "\n",
    "]\n",
    "\n",
    "model_inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "generated_ids = model.generate(model_inputs, max_new_tokens=100, do_sample=True)\n",
    "\n",
    "tokenizer.batch_decode(generated_ids)[0]\n",
    "\"The expected output\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
