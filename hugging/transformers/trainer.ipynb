{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/v4.44.2/en/main_classes/trainer#trainer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.gopenai.com/how-to-resolve-runtimeerror-cuda-out-of-memory-d48995452a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiagoads/Workspace/Programas/miniconda3/envs/transformers/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0c3d3f24a543bbbec389836307edcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-08-26 22:15:34.288525: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14653fab97334ff5a2e4a453d19006ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8530 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9524, 'grad_norm': 0.6996574997901917, 'learning_rate': 1.8827667057444317e-05, 'epoch': 0.06}\n",
      "{'loss': 1.092, 'grad_norm': 0.3950474262237549, 'learning_rate': 1.7655334114888628e-05, 'epoch': 0.12}\n",
      "{'loss': 1.1472, 'grad_norm': 38.29890823364258, 'learning_rate': 1.6483001172332943e-05, 'epoch': 0.18}\n",
      "{'loss': 0.9417, 'grad_norm': 195.2352294921875, 'learning_rate': 1.5310668229777258e-05, 'epoch': 0.23}\n",
      "{'loss': 0.8948, 'grad_norm': 0.15859559178352356, 'learning_rate': 1.4138335287221572e-05, 'epoch': 0.29}\n",
      "{'loss': 0.811, 'grad_norm': 0.293508380651474, 'learning_rate': 1.2966002344665887e-05, 'epoch': 0.35}\n",
      "{'loss': 0.9282, 'grad_norm': 0.12572962045669556, 'learning_rate': 1.17936694021102e-05, 'epoch': 0.41}\n",
      "{'loss': 0.7846, 'grad_norm': 0.08798622339963913, 'learning_rate': 1.0621336459554515e-05, 'epoch': 0.47}\n",
      "{'loss': 0.9664, 'grad_norm': 0.25048723816871643, 'learning_rate': 9.449003516998828e-06, 'epoch': 0.53}\n",
      "{'loss': 0.7778, 'grad_norm': 0.4948570430278778, 'learning_rate': 8.276670574443143e-06, 'epoch': 0.59}\n",
      "{'loss': 0.7757, 'grad_norm': 0.07568216323852539, 'learning_rate': 7.1043376318874565e-06, 'epoch': 0.64}\n",
      "{'loss': 0.8686, 'grad_norm': 0.009657660499215126, 'learning_rate': 5.932004689331771e-06, 'epoch': 0.7}\n",
      "{'loss': 0.8164, 'grad_norm': 828.2711791992188, 'learning_rate': 4.759671746776085e-06, 'epoch': 0.76}\n",
      "{'loss': 0.8214, 'grad_norm': 0.44943174719810486, 'learning_rate': 3.587338804220399e-06, 'epoch': 0.82}\n",
      "{'loss': 0.7671, 'grad_norm': 0.11232341825962067, 'learning_rate': 2.415005861664713e-06, 'epoch': 0.88}\n",
      "{'loss': 0.7627, 'grad_norm': 0.029221564531326294, 'learning_rate': 1.2426729191090272e-06, 'epoch': 0.94}\n",
      "{'loss': 0.743, 'grad_norm': 55.32827377319336, 'learning_rate': 7.033997655334116e-08, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1568f1ac84224e23bb361644c613a331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8523743152618408, 'eval_runtime': 173.253, 'eval_samples_per_second': 6.153, 'eval_steps_per_second': 6.153, 'epoch': 1.0}\n",
      "{'train_runtime': 6241.3634, 'train_samples_per_second': 1.367, 'train_steps_per_second': 1.367, 'train_loss': 0.8723370741009013, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8530, training_loss=0.8723370741009013, metrics={'train_runtime': 6241.3634, 'train_samples_per_second': 1.367, 'train_steps_per_second': 1.367, 'total_flos': 2244337302220800.0, 'train_loss': 0.8723370741009013, 'epoch': 1.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    #data_collator=data_collator,\n",
    "    #compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b5c7fbce144c778eb7e20ce607413b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5faf9153353143da9bec6dc11cd0870c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/thiagoads/bert-base-cased/commit/099e202f3c24fb195c89efa3d9289c149be9eaef', commit_message='Upload BertForSequenceClassification', commit_description='', oid='099e202f3c24fb195c89efa3d9289c149be9eaef', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
