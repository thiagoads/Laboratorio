{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMs com Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descomente a linha específica caso precise resetar variável\n",
    "# os.unsetenv(\"LANGCHAIN_API_KEY\")\n",
    "# os.unsetenv(\"OPENAI_API_KEY\")\n",
    "# os.unsetenv(\"GOOGLE_APPLICATION_CREDENTIALS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# informe api key p/ langchain smith tracking sevice\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(content=\"Hi!\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maneira mais indicada de ler o resultado\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# garanta que o token está certo, pq acessar c/ token errado tb paga\n",
    "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f518f9ac790>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f518f945610>, model_name='gpt-4', openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pode passar modelo como parâmetro\n",
    "model = ChatOpenAI(model=\"gpt-4\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invocando o modelo\n",
    "result = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Ciao!' response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 20, 'total_tokens': 23}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-447f1a66-fc25-4069-b959-56b9b8979669-0' usage_metadata={'input_tokens': 20, 'output_tokens': 3, 'total_tokens': 23}\n",
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "# imprimir predict\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "# maneira mais indicada de ler o resultado\n",
    "print(parser.invoke(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melhor ainda é criar um cadeia de chamadas\n",
    "# invocando o model e o parser em sequência\n",
    "chain = model | parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# a biblioteca não está disponível no conda-forge\n",
    "# podr isso tem que ser instalada com o cmd pip.\n",
    "%pip install -qU langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "# informar aqui o caminho para as credenciais do google\n",
    "# credencials deve ser de conta de serviço c/ permissão p/ VertexAI API\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/path/to/credentials\"\n",
    "\n",
    "model = ChatVertexAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = model | parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='Translate the following into italian:'), HumanMessage(content='Hi!')]\n",
      "[SystemMessage(content='Translate the following into italian:'), HumanMessage(content='Hi!')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following into {language}:\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([(\"system\", system_template), (\"user\", \"{text}\")])\n",
    "\n",
    "result = prompt_template.invoke({\"language\": \"italian\", \"text\": \"Hi!\"})\n",
    "\n",
    "print(result)\n",
    "\n",
    "print(result.to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ciao! \\n\\nWhat would you like me to translate for you? \\n\\nJust provide the text or phrase in any language, and I'll do my best to translate it into Italian for you. \\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encadeando todos os componentes com pipe\n",
    "chain = prompt_template | model | parser\n",
    "chain.invoke({\"language\": \"italian\", \"text\": \"Hi!\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langserve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora execute o arquivo serve.py para servir o modelo com fastapi e langserve.\n",
    "\n",
    "Isso irá subir um serviço de api na porta 8000: http://localhost:8000/chain/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao! Come posso aiutarti? \\n\\n(Hello! How can I help you?) \\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "remote_chain = RemoteRunnable(\"http://localhost:8000/chain/\")\n",
    "remote_chain.invoke({\"language\": \"italian\", \"text\": \"hi\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
